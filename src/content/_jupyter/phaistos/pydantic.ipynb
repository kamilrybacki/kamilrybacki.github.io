{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic model dump - what's inside?\n",
    "\n",
    "In this quick example we will create a Pydantic model and dump it to see what's inside.\n",
    "Here I will start to make one distinction:\n",
    "\n",
    "* **Decorated methods** that serve as definitions for validators on various fields will be called straight-up **validators** by me,\n",
    "* The limits such as `min_length`, `max_length`, `min_value`, `max_value` etc. will be called **constraints**,\n",
    "defined as additional arguments to the `Field` constructor.\n",
    "\n",
    "This is to make the distinction between the two clearer, which wil lcome in handy when we will be looking at the dumped model\n",
    "and, later, creating the library which is the main goal of this article.\n",
    "\n",
    "So first, let's create a simple Pydantic model with one validator and two constraints on the `age` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic\n",
    "import json\n",
    "import logging\n",
    "\n",
    "\n",
    "class Nested(pydantic.BaseModel):\n",
    "    name: str\n",
    "    age: int = pydantic.Field(ge=0, le=80)\n",
    "\n",
    "    @pydantic.field_validator('age')\n",
    "    def check_age(cls, value):\n",
    "        if value < 18:\n",
    "            raise ValueError('You need to be an adult to use this service.')\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check if all bells and whistles are in good order by feeding some data to the model and checking if it's valid.\n",
    "Let's do that for a list of differing ages, since we know that anything in the range from $0$ to $18$ **and** above $80$ is invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# We can see if validators/constraints are working\n",
    "# by trying to create a model with invalid and valid values.\n",
    "# For invalid values, we expect a ValidationError to be raised.\n",
    "# For valid values, we expect the model to be created successfully.\n",
    "for age in [-1, 0, 17, 18, 80, 81]:\n",
    "    try:\n",
    "        Nested(name='John', age=age)\n",
    "        logging.info(f'John is {age} years old.')\n",
    "    except pydantic.ValidationError as e:\n",
    "        logging.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "TIMESTAMP_START = datetime.datetime.now() - datetime.timedelta(days=100)  # All timestamps will be relative to this one\n",
    "\n",
    "\n",
    "class ModelWithDatetime(pydantic.BaseModel):\n",
    "    created_at: str\n",
    "\n",
    "    @pydantic.field_validator('created_at')\n",
    "    def check_created_at(cls, value):\n",
    "        iso_formatted_value = datetime.datetime.fromisoformat(value)\n",
    "        if iso_formatted_value - TIMESTAMP_START < datetime.timedelta(days=0):\n",
    "            raise ValueError('The timestamp is too old.')\n",
    "        return iso_formatted_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is a simple example of a context-dependent model - it checks the date 100 days before the current date\n",
    "and then validates if passed date is not older than that.\n",
    "\n",
    "This is a simple example of a validator that uses a global context to validate the field, because:\n",
    "\n",
    "* `datetime` need to be imported from the `datetime` module and included in the current `globals()`,\n",
    "* `datetime.now()` is a function that is called during the model creation and is not a part of the model itself,\n",
    "* the `TIMESTAMP_START` constant is a module-wide constant that is used in the validator.\n",
    "\n",
    "Let's check how this model will behave when the global context changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will employ a trick to remove the datetime module from the globals() dictionary,\n",
    "# so it is not available to the unpickled object.\n",
    "if 'datetime' in globals():\n",
    "    del globals()['datetime']\n",
    "\n",
    "# We can check it by trying to access the datetime module\n",
    "try:\n",
    "    datetime.datetime.now()\n",
    "except NameError as e:\n",
    "    logging.error(f'Failed to access the datetime module: {e}')\n",
    "\n",
    "# Now we will try to create an instance of the model\n",
    "try:\n",
    "    ModelWithDatetime(created_at='1410-07-15T00:00:00')  # This is the date of the Battle of Grunwald\n",
    "except NameError as e:\n",
    "    logging.error(f'Failed to create an instance of the model: {e}')\n",
    "\n",
    "# Now we will try to create an instance of the model AFTER we have restored the datetime module\n",
    "\n",
    "import datetime\n",
    "\n",
    "try:\n",
    "    ModelWithDatetime(created_at='1410-07-15T00:00:00')\n",
    "except pydantic.ValidationError as e:\n",
    "    logging.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha! We got an `NameError` error, because the `datetime` module is not available in the validator function in a clean Python environment.\n",
    "After re-importing the missing module, we can see that the model model performs the validation as expected, hence the `ValidationError`\n",
    "is raised for the date that is older than 100 days.\n",
    "\n",
    "This means that any dependencies used inside of the valdiator functions need to be installed and re-imported in the new environment\n",
    "in order to work properly. One way to fix this would be to move the importing of the `datetime` module to the\n",
    "source code of validator function, but this is not a good practice, because it makes the code less readable and harder to maintain.\n",
    "\n",
    "However, we will bite the bullet and try this approach to see if it will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, remove datetime\n",
    "if 'datetime' in globals():\n",
    "    del globals()['datetime']\n",
    "\n",
    "\n",
    "class ModelWithDatetimeRedux(pydantic.BaseModel):\n",
    "    created_at: str\n",
    "\n",
    "    @pydantic.field_validator('created_at')\n",
    "    def check_created_at(cls, value):\n",
    "        \"\"\"\n",
    "            What we do is we basically try to \"pack\" the whole context of the function here\n",
    "        \"\"\"\n",
    "        import datetime\n",
    "        TIMESTAMP_START = datetime.datetime.now() - datetime.timedelta(days=100)\n",
    "\n",
    "        iso_formatted_value = datetime.datetime.fromisoformat(value)\n",
    "        if iso_formatted_value - TIMESTAMP_START < datetime.timedelta(days=0):\n",
    "            raise ValueError('The timestamp is too old.')\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gone with the datetime module again\n",
    "if 'datetime' in globals():\n",
    "    del globals()['datetime']\n",
    "\n",
    "# Now we will try to create an instance of the model, which should pass\n",
    "\n",
    "try:\n",
    "    ModelWithDatetimeRedux(created_at='1410-07-15T00:00:00')\n",
    "except pydantic.ValidationError as e:\n",
    "    logging.error(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, cool, this approach works and may be used to move around our Pydantic models from one environment to another,\n",
    "since the validators are now self-contained and do not depend on any global context. We need to check a couple of things.\n",
    "\n",
    "First - how this works out for nested models, since we can have fields that are Pydantic models themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nested(pydantic.BaseModel):\n",
    "    name: str\n",
    "    age: int = pydantic.Field(ge=0, le=80)\n",
    "\n",
    "    @pydantic.field_validator('age')\n",
    "    def check_age(cls, value):\n",
    "        if value < 18:\n",
    "            raise ValueError('You need to be an adult to use this service.')\n",
    "        return value\n",
    "\n",
    "\n",
    "class Root(pydantic.BaseModel):\n",
    "    description: str\n",
    "    nested: Nested\n",
    "\n",
    "# Let's see what information is available in the JSON dump of our model\n",
    "nested_model = Root(\n",
    "    description='A model with a nested model',\n",
    "    nested=Nested(\n",
    "        name='John',\n",
    "        age=18\n",
    "    )\n",
    ")\n",
    "\n",
    "# We will confirm that the model is created successfully,\n",
    "# and nested model is also created successfully as one of the fields\n",
    "logging.info(\n",
    "    json.dumps(  # This method is just for indentation only\n",
    "        Nested.model_json_schema(),  # This is a V2 version of the schema dump\n",
    "        indent=2\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, validation for $-1$, $0$, $18$ and $81$ failed, while $1$, $17$, $19$ and $80$ passed.\n",
    "This means that both our validator and constraints are working as expected.\n",
    "\n",
    "## Serializing the model\n",
    "\n",
    "Now, let's serialize the model to see what's inside. Pydantic allows us to dump the model to a dictionary, which we can then print out,\n",
    "using the `model_json_schema` (previously it was `schema_json`) method. As we can see, the model is serialized to a dictionary with\n",
    "contains only information about the **contraints** applied to the fields, but no mention is found of the **validators**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what information is available in the JSON dump of our model\n",
    "logging.info(\n",
    "    json.dumps(  # This method is just for indentation only\n",
    "        Root.model_json_schema(),  # This is a V2 version of the schema dump\n",
    "        indent=2\n",
    "    )\n",
    ")\n",
    "logging.info(\n",
    "    Root.schema_json(indent=2)\n",
    ")  # This is a V1 version of the schema dump\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the more lower-lever `dict()` method on the model instance to see if it will give us more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance = Nested(name='John', age=18)\n",
    "logging.info(\n",
    "    Root.dict(model_instance)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far no hit on the validators. Let's just use the Python built-in `__dict__` attribute to see if we can find anything useful there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dict_of_model = Root.__dict__\n",
    "logging.info(whole_dict_of_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we get out of this?\n",
    "\n",
    "First of all, we can see that the `__dict__` attribute of the model class contains all the fields that we defined in the model,\n",
    "**together** with definitions of validator functions linked to named fields. This means, that we can try to **programatically**\n",
    "create a class inheriting from `BaseModel` and add all the fields and validators to it by accessing correct, private attributes of the model instance.\n",
    "\n",
    "But why any JSON dumps of our model did not contain this information? The answer is simple - Pydantic does not serialize the validators,\n",
    "because the underlying serializers do not know how to handle them. They are **functions** with specific **closures** that need to be\n",
    "**reconstructed** in order to be used. Similarly, reading the documentation for JSON schemas in Pydantic, we can see that there\n",
    "is no straightforward way to serialize models and load them back via library's API.\n",
    "\n",
    "Let's check if we can reconstruct our nested model from the serialized form of the `__dict__` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dump = dict(**Root.__dict__)\n",
    "\n",
    "# Start with the built-in type function to create a new class\n",
    "try:\n",
    "    reconstructed_model = type(\n",
    "        'NestedModel',\n",
    "        (pydantic.BaseModel,),\n",
    "        model_dump\n",
    "    )\n",
    "except pydantic.PydanticUserError as error:\n",
    "    logging.error(f'Failed to reconstruct the model: {error}')\n",
    "\n",
    "# Maybe we can try to filter out the object's attributes from the model's dictionary,\n",
    "# and then try to reconstruct the model using Pydantic API?\n",
    "\n",
    "object_dict = object.__dict__  # This is the dictionary of the object's attributes, a base class for all objects in Python\n",
    "filtered_model_dump = {k: model_dump[k] for k in model_dump if k not in object_dict}  # This leaves out Pydantic's BaseModel-specific attributes\n",
    "\n",
    "validators_from_dict = filtered_model_dump.get('__validators__', {})\n",
    "reconstructed_model = pydantic.create_model(\n",
    "    'NestedModel',\n",
    "    __base__=pydantic.BaseModel,\n",
    "    __validators__=validators_from_dict,\n",
    "    **{\n",
    "        annotation: (filtered_model_dump['__annotations__'][annotation], ...)\n",
    "        for annotation in filtered_model_dump['__annotations__']\n",
    "    }\n",
    ")\n",
    "reconstructed_model_instance = reconstructed_model(\n",
    "    description='A nested model',\n",
    "    nested=Nested(\n",
    "        name='John',\n",
    "        age=18\n",
    "    )\n",
    ")\n",
    "\n",
    "logging.info(reconstructed_model_instance.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, seems like we have found out way to reconstruct the model. It may no be as straightforward as we would like it to be, but it clearly works.\n",
    "The validators seem to be taken into the account, since the validation of the nested model works as expected. But, what if we start from scratch,\n",
    "meaning that there is no `Model` class defined in the current environment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Nested' in globals():\n",
    "    del globals()['Nested']\n",
    "if 'Root' in globals():\n",
    "    del globals()['Root']\n",
    "\n",
    "# Now we can try to reconstruct the Root model, having ONLY the filtered dictionary available to us\n",
    "\n",
    "reconstructed_model = pydantic.create_model(\n",
    "    'NestedModel',\n",
    "    __base__=pydantic.BaseModel,\n",
    "    __validators__=validators_from_dict,\n",
    "    **{\n",
    "        annotation: (filtered_model_dump['__annotations__'][annotation], ...)\n",
    "        for annotation in filtered_model_dump['__annotations__']\n",
    "    }\n",
    ")\n",
    "\n",
    "try:\n",
    "    reconstructed_model_instance = reconstructed_model(\n",
    "        description='A nested model',\n",
    "        nested=Nested(\n",
    "            name='John',\n",
    "            age=18\n",
    "        )\n",
    "    )\n",
    "except NameError as e:\n",
    "    logging.error(f'Failed to create an instance of the model: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the main pitfall we encounter in this case. The `Model` class is not defined in the current environment, so we cannot\n",
    "reconstruct the model from the serialized form of the `__dict__` attribute. This means that we need to have the `Model` class\n",
    "defined in the current environment in order to reconstruct the `Root` model from the serialized form of the `__dict__` attribute.\n",
    "\n",
    "The second pitfall is actually easy to show - if we choose the output (even filtered) of the `__dict__` attribute of the model instance\n",
    "then we will be unable to serialize it to a form that would be suitable for exporting such as JSON or YAML. This is because the\n",
    "`__dict__` attribute contains references to the functions that are not serializable.\n",
    "\n",
    "Let's quickly define another nested model and try to serialize it to see if we can reconstruct it from the serialized form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Address(pydantic.BaseModel):\n",
    "    street: str\n",
    "    city: str\n",
    "    zip: str\n",
    "\n",
    "    @pydantic.field_validator('zip')\n",
    "    def check_zip(cls, value):\n",
    "        if len(value) != 5:\n",
    "            raise ValueError('ZIP code must be exactly 5 characters long.')\n",
    "        return value\n",
    "\n",
    "class WorkInfo(pydantic.BaseModel):\n",
    "    company: str\n",
    "    position: str\n",
    "    salary: float = pydantic.Field(ge=0)\n",
    "\n",
    "# This will be our new Root model\n",
    "class Person(pydantic.BaseModel):\n",
    "    name: str\n",
    "    age: int = pydantic.Field(ge=0)\n",
    "    address: Address\n",
    "    occupation: WorkInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to JSON dump this bad boi to see if it can be exported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_person_dump = {k: Person.__dict__[k] for k in Person.__dict__ if k not in object_dict}\n",
    "\n",
    "# Dump the model to JSON\n",
    "try:\n",
    "    person_as_json = json.dumps(filtered_person_dump, indent=2)\n",
    "except TypeError as e:\n",
    "    logging.error(f'Failed to serialize the model: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we can always `pickle` our data and go from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Let's pickle the model\n",
    "try:\n",
    "    pickled_model = pickle.dumps(filtered_person_dump)\n",
    "except TypeError as e:\n",
    "    logging.error(f'Failed to pickle the model: {e}')\n",
    "\n",
    "# Maybe the pickling of the whole model will work?\n",
    "try:\n",
    "    pickled_model = pickle.dumps(Person)\n",
    "    logging.info('Model pickled successfully!')\n",
    "except TypeError as e:\n",
    "    logging.error(f'Failed to pickle the model: {e}')\n",
    "# Let's pickle the model\n",
    "try:\n",
    "    pickled_model = pickle.dumps(filtered_person_dump)\n",
    "except TypeError as e:\n",
    "    logging.error(f'Failed to pickle the model: {e}')\n",
    "\n",
    "# Maybe the pickling of the whole model will work?\n",
    "try:\n",
    "    pickled_model = pickle.dumps(Person)\n",
    "    logging.info('Model pickled successfully!')\n",
    "except TypeError as e:\n",
    "    logging.error(f'Failed to pickle the model: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! The anwser was so simple, we only needed to use the good old `pickle` module to serialize the model to a bytes object. Let's see how it looks like, so we can try to come up with a way to maintain the model in a serialized form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(pickled_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly, just how a random jumble of bytes would look like. More over, the **first** pitfall is still in place - we need to have nested models defined in the current environment in order to reconstruct the model from the serialized form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [Person, Address, WorkInfo]:\n",
    "    if model.__name__ in globals():\n",
    "        del globals()[model.__name__]\n",
    "\n",
    "# Now we will try to unpickle the model\n",
    "try:\n",
    "    unpickled_model = pickle.loads(pickled_model)\n",
    "    logging.info('Model unpickled successfully!')\n",
    "except AttributeError as e:\n",
    "    logging.error(f'Failed to unpickle the model: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These ramblings show that available solutions always come with some kind of trade-off. We can either:\n",
    "\n",
    "* serialize the model to a dictionary and lose the validators,\n",
    "* serialize the model to a bytes object and lose the ability easily analyze the model's structure.\n",
    "\n",
    "In both cases, we need to be **aware** that any nested models need to be defined in the current environment in order to reconstruct the model from the serialized form.\n",
    "So, if You model is dependent on some other models - You've got two pickles to pass around, and the complexity of the model grows with each nested model.\n",
    "\n",
    "This is a clear sign of a need a better way to serialize and deserialize Pydantic models, so we can easily export and import them to and from different environments.\n",
    "\n",
    "Back to the drawing board..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
