---
title: "Particles of Rust II: Balls and sticks"
date: "2024-02-12"
description: "Fill our simulation box with particles and simulate their interactions"
tags: ["rust", "molecular dynamics", "simulation", "particles", "potential"]
image:
  thumbnail: "por2"
  hero: "por2"
  alt: "Bond between atoms"
---

## Keep it cool ‚ùÑÔ∏è

Right now, we have our first building blocks of molecular dynamics simulations ready - the definition of a bounding box
that encompasses our system and the definition of a particle. By providing the information about their relative positions
within a repeatable pattern (a unit cell of a crystal lattice) we can construct three-dimensional structures of any
crystalline material. Of course, if we want this structure can also be of any kind - even the completely random one,
since right now we are passing each particle's position manually in the simulation script.

So, the box and balls of our atomistic machine are up and running. Now, it's time to connect the spheres modeling
the atoms with "sticks", or in more scientific terms - with the **potential energy function**. Right now we will not
concern ourselves about implementing their behavior over time i.e. the dynamics of the system but rather focus on
the static picture of our simulation box.

By correct construction of the energetics of the interactions between the
particles, we will ensure that any mishaps we encounter during the integration of the equations of motion are not due to
the incorrect modeling of the potential energy landscape in the simulated lattice. **And believe me**, there is a plethora
of caveats that await us in the upcoming Newtonian puzzles, that are mostly related to the numerical precision of methods
we will choose. But, let's not get ahead of ourselves and focus on the task at hand.

This ignorance of dynamics is not uncommon and even has its own name - **molecular statics** (duh ü§∑‚Äç‚ôÇÔ∏è). It is a
computationally less demanding approach to molecular dynamics simulations, where we are not interested in the
time evolution of the system but rather in the **equilibrium** state of the system. And as nature often has it,
this equilibrium is the situation where the forces acting on the particles are balanced and the system is at rest, so
**their overall energy is at minimum**. Funny enough, physicists identify such states as ones where, hypothetically,
the temperature of the system is absolute zero - as in, there is totally no movement of any particles, they are at 0 Kelvin.
So we're venturing into a very cold world, indeed. ü•∂

## First encounter with the moonspeak üåå

The potential energy function is a mathematical model that describes the interactions between particles in a system.
Speaking 100% technically, it is a function of the relative positions of two particles and it returns the potential
energy of interaction between them, expressed in the same units as any other type of energy (e.g. Joules). There
is a **multitude** of potential energy models, that have been established over the years. Some of them try to
expand upon the information required to correctly calculate interaction energy for a given pair of particles by
introducing additional parameters that are connected to, for example, the closest neighborhood of each particle
or the physical properties of the particles themselves (like their electronic structure). 

Here, for the sake of simplicity, we will stick to the most trivial potential energy model - the **Lennard-Jones potential**.
It is a model that describes the interaction between two neutral atoms or molecules. It is a sum of two terms - the first
one is a repulsive term, that is dominant at short distances and the second one is an attractive term, that is dominant
at long distances. This ensures that if particles start to get too close to each other, they will repel each other
to prevent their overlap and if they are too far away, they will attract each other to form a stable bond. So, in a way,
it is a model that describes the behavior of a pair of particles as if they were connected by a spring. You can
try right now to get a spring and squish it a bit, then release it and observe its behavior. It will, very shortly,
oscillate or do the ["boioioioing" thing], expanding and contracting until it reaches the equilibrium state - the state
where its dimensions come back to normal. I have found a very nice animation (courtesy of [physics-animations.com]), which
You can see below. The behavior of those two bonded particles will be very similar to the explained behavior of the spring.
Of course, we neglect here that there are any other phenomena that may lead to this movement being damped like the friction of
the air or the internal friction of the spring itself (You can imagine internal "layers" of the spring's material rubbing against
each other on the microscopic scale, wild, right? ü§Ø).

<CaptionedImage
  src="/assets/images/por_2_lj_oscillation.gif"
  alt="A model for two bonded particles - two balls and spring"
/>

So we need that dual nature of the potential energy function to model the interactions between our particles and this will
translate into this oscillating motion when we integrate the equations of motion for our particles that will try to maintain
their state around some equilibrium. But You may be a little bit confused right now - I keep talking about potential **energy**
and **force** somewhat interchangeably. There is a simple explanation for that, that can be shown using simple, physical hieroglyphs.

### Unleashing the force üå™Ô∏è

Okay, so maybe You remember from Your high school physics classes that there is something as a **work**, in physical
sense, of course. It is a measure of the energy transfer that occurs when an object is moved over a distance by an
external force at a constant speed. This means, that over some **distance** (let's call it `d`) we apply some **force**
(let's call it `F`) and the object effectively gains some **energy** (let's call it `W`, as work). This relationship
can be briefly expressed as:

$$W = F \cdot d$$

A very graphical representation of this energy transfer would be a bullet that hits a wall. When the collision occurs, 
the bullet starts instantly to act with great force upon a fragment of the wall it hits, transferring its kinetic energy to the wall.
But this energy can also be thought of as a portion of work that the bullet has done on the wall, which forces the wall to adjust its position
by a distance calculated from the equation above: $$d = \frac{W}{F}$$.

However, we can also perform another transformation of this equation, to express the force acting on the object in terms of the work done on it:

$$F = \frac{W}{d}$$

which tells us that if we somehow measure or calculate the amount of work done between two objects separated by a distance `d`, we can
also calculate the force that was acting between them. But why? Well, we can imagine this force as trying to maintain the optimal distance
between those bodies, such that they will not be too close to each other (which would result in a repulsive force) or too far away from each other
(which would result in an attractive force). If they are not in this ideal state, each of them will have to perform some **work** to modify this
distance and its amount will be dependent on how far they are from this hypothetical **equilibrium**.

So, what if they are at this perfect distance from each other? Well, then the force acting between them will be zero, since they will not be trying to
change their relative position. Let's express this for our pair of objects as some perfect (equilibrium) distance $r_0$ for which: $F(r_0) = 0$ i.e. nothing happens.
**Any** deviation from this distance will result in a force acting between them, that will try to bring them back to this equilibrium.
We can write this deviation as a change in distance $\Delta r = r - r_0$ and the force acting between them as $F(\Delta r)$. Going back to our
equation for the force acting between them, we can express it as:

$$F(\Delta r) = -\frac{W(\Delta r)}{\Delta r}$$

where $W(\Delta r)$ is the work that would be needed to compensate for this sudden change and enforce back the equilibrium state.

Wait, why the minus? ü§î Well, remember what is the role of the force $F$. It tries to revert the current state of the system to the
original one, so it will be always antagonistic to the change that has occurred. So, the sign of $F$ must always be opposite to $\Delta r$
and that's why we have this minus sign in the equation above.

At this point, we must do a little switcheroo and say that this work will be some function dependent solely on the distance between particles.
In physics, a function that returns a numerical (scalar) value, which can be used to express the magnitude of some directional quantity
(like force, for example) is called a **potential**. In other words, this potential function will spit out a number that will tell us
how strong the interaction between particles is at a given distance **and** can be directly used to calculate the measure of this
interaction a.k.a force. We will denote this function as $U(\Delta r)$ and call it the **potential energy function**.

The last mental gymnastic we can perform is by saying that if $\Delta r$ can be expressed as a difference between a current
position of the object and some predefined constant (which is the equilibrium distance $r_0$) that will not change over time,
then the real dependence of potential function $U$ is on position $r$ directly. Same with the force acting between particles ($F$).
This may seem like we want to cheat a little bit and just substitute one thing for another, but mathematically speaking
the $r_0$ is a constant and the real argument of the function is $r$ - the equilibrium distance is not a dynamic measure.
Imagine back again a spring - its original, non-deformed length depends only on how it was manufactured and on the material
from which it is made. Similarly, our system also has its equilibrium state which can be derived from its composition
(like, which atoms constitute its makeup and what are their properties). So, our equation for the force acting between objects
can be expressed as:

$$F(r) = -\dfrac{U(r)}{\Delta r}$$

This is true for a significant change in the position, so for $\Delta r >> 1$ (much bigger than one unit of distance).
Now, let's go back to our cases of atoms connected by the aforementioned forces. We can imagine that any movement
measured at their scale will be super **minuscule** or even **infinitesimal** (infinitely small). This means that
our $\Delta r$ will be tending to zero, which allows us to use one of the magical tools of calculus - the derivative.
We can express the force acting between particles as. If we prefix very small amounts of quantities in our equation
with $d$ (like $dr$), we can express the force acting between particles as:

$$F(r) = -\dfrac{dU(r)}{dr}$$

Does that mean that we will have to measure those very small changes in distance? Well, no. The derivative allows us
to take the function that describes the potential between particles ($U(r)$) and then transform it using a set
of differentiation rules into a new function that will describe the force acting between particles ($F(r)$). This
is **huge** for us, because we will be able to calculate those forces **directly** via a mathematical function
implemented as a piece of code.

This sets up a first set of goals for us:

1. Find the mathematical expression for the Lennard-Jones potential energy function.
2. Quickly calculate its derivative to obtain the equation for the force acting between particles.
3. Implement a function that will take the distance between particles as an argument and return the force acting between them.
4. Do the calculation for all pairs of particles in our system and sum up the forces acting on each particle to obtain the net force acting on it.

Let's blitz through the mathematical part and then delve into more programming side of things.

## Slippery slopes of Lennard-Jones üèîÔ∏è

The Lennard-Jones potential is like a baby's first model to implement for the purposes of molecular dynamics simulations.
Finding an expression for it takes [literally one minute] and has a rather simple form with two rational terms:

$$U(r) = 4\epsilon\left[\left(\dfrac{\sigma}{r}\right)^{12}-\left(\dfrac{\sigma}{r}\right)^6\right]$$

To get a better hand on its inner workings, let's investigate it using some good ol' Python and the `matplotlib` library.

import JupyterLiteEmbed from "@components/markdown/JupyterLiteEmbed"

<JupyterLiteEmbed
  size="750px"
  file="por/lj.ipynb"
  kernel="python"
  client:load
/>

After our excursion, we got two major pieces of information. The first one is the expression for the **force of interactions**
between particles derived from Lennard-Jones potential (note the minus again, it was explained in the last Markdown cell):

$$F(r) = - 4 \epsilon \left(\frac{6 \sigma^{6}}{r^{7}} - \frac{12 \sigma^{12}}{r^{13}}\right)$$

that can be visualized using the graph generated at the end of the Jupyter Notebook that was previously used,
which I took the liberty to enhance a little bit to explain its characteristics and relationship with
the equation above:

<CaptionedImage
  src="/assets/images/por_2_lj_whole.png"
  alt="Lennard-Jones potential (blue curve) and force (red curve) with characteristic points and quantities shown"
/>

First of all, an interesting fact is that even though we say that there is an equilibrium in our system at
some predefined distance $r_0$, it is not a state of zero potential energy - this means that even though interactions
between bodies cancel out, they are still **bonded** and require external energy to compensate for this potential well.
For now, I have denoted this energy stored in their shared bond as $U_\mathrm{min}$ (minimal value of potential).
Introducing new designations in physics should always make Your laziness senses tinglin' üï∑Ô∏è, because that means
keeping track of another Latin or Greek squiggle in our equations. We must try to relate it to things we already know,
thus reducing the number of exotic runes we will inscribe onto this digital parchment üìú.

Looking at our graphs and reaching back to the mathematics, we see that this minimum value exists for such $r_\textrm{min}$
that the expression for $F(r)$ reaches zero, so in our moonspeak dialect üåõ this means: $F(r_\textrm{min}) = 0$,
which allows us to find a recipe for this distance **in terms of $\sigma$ and/or $\epsilon$ parameters**:

$$F(r_\textrm{min}) = 0 \Rightarrow - 4 \epsilon \left(\dfrac{6 \sigma^{6}}{r^{7}_\textrm{min}} - \dfrac{12 \sigma^{12}}{r^{13}_\textrm{min}}\right) = 0~~~/ \cdot (-4\varepsilon)$$

$$\dfrac{6 \sigma^{6}}{r^{7}_\textrm{min}} = \dfrac{12 \sigma^{12}}{r^{13}_\textrm{min}}~~~/ \cdot r^{13}_\textrm{min}~~~/ : 12$$

$$r_\textrm{min}^6 = 2\sigma^6 \Rightarrow r_\textrm{min} = 2^{\frac{1}{6}}\sigma$$

As we can see this result goes in line with our observation in the Jupyter Notebook, where playing around with the value
of $\sigma$ parameter, shifted our graphs horizontally i.e. changed the point where it was intersecting the $y$-axis.
Now, leveraging pure mathematics, we can say that this is also the distance at which the potential $U(r)$ has its minimum
because **the location of the minimum of some function is equal to the argument for which its first derivative equals zero**.
So, reaching again for the occult symbols, this means that: $U(r_\textrm{min})=U_\textrm{min}$ (hence the subscript).
Knowing that, let's substitute the $r$'s for $r_\textrm{min}$'s and see what we get:

$$U(r_\textrm{min}) = 4\epsilon\left[\left(\dfrac{\sigma}{r_\textrm{min}}\right)^{12}-\left(\dfrac{\sigma}{r_\textrm{min}}\right)^6\right] = 4\varepsilon\left[\left(\dfrac{\sigma}{2^{\frac{1}{6}}\sigma}\right)^{12}-\left(\dfrac{\sigma}{2^{\frac{1}{6}}\sigma}\right)^6\right] = $$

$$ = 4\epsilon\left[\left(\dfrac{1}{2^{\frac{1}{6}}}\right)^{12}-\left(\dfrac{1}{2^{\frac{1}{6}}}\right)^6\right] = 4\varepsilon \left(\dfrac{1}{4} - \dfrac{1}{2}\right) = -\varepsilon$$

### Limiting our horizons ‚úÇÔ∏è

Now it is obvious why changing the $epsilon$ parameter scaled our graphs vertically - **it is the depth of the potential well itself!**.
Even the minus doubles down on this fact since, as we saw on the plots because the minimum of energy is always below zero.
This means that the combination of those two Lennard-Jones parameters controls the location and depth of the potential minimum
or, in more physical terms, **the strength of interatomic bonding**. In the graph above we can also see, that the potential
tends to zero if we move along its right side, so up the potential well. In theory, the potential will be equal to zero
if the distance $r$ reaches infinity ($r \rightarrow \infty$).

We can also look at this behavior the other way around - if we give a portion of energy equal to $\epsilon$ to our bonded bodies, 
then we will move its potential energy to the point of $U(r) = 0$, which would mean that they are infinitely far from each other. 
**We would break the bond** and that is the role of this potential well in terms of their interaction - it tries to keep the two atoms bonded
to each other, but if a sufficient amount of energy is packed into the system then it will yield and let the particles
free. ü•è You can visualize it as a ball that continuously slides up and down a U-shaped valley - on its own it
doesn't have enough energy to overcome the height of the hills surrounding it and after any disturbance, it will
gravitate towards the bottom (please don't make any comparison between this phenomenon and the occasional manifestation of human folly ü§´).

<CaptionedImage
  src="/assets/images/por_2_potential_well.gif"
  alt="An approximation for oscillations around potential well"
/>

But what about bodies that are far from each other, from the point of view of Lennard-Jones potential of course?
What does "far" even mean in this context? Well, we can see that the potential energy function tends to zero
but it does not reach it at some finite distance. However, after some distance, the value of the potential energy
(and the force acting between particles) will be so small that it will be negligible in comparison to other forces
occurring within the system, even by several orders of magnitude. This means that we can **cut off** the potential
or in other words - **limit its range**.

This is a very common practice in molecular dynamics simulations, where
we want to limit the computational cost of calculating interactions between particles that are very far from each other.
So we would need to introduce a new parameter that will represent the distance at which we will cut off the potential,
normally denoted as $r_\textrm{cut}$. This means that the potential energy function of interactions between pairs of atoms
will be calculated only if their distance is smaller than $r_\textrm{cut}$. Cool, so at each calculation of forces
between atoms we will just calculate the distance between their pairs, then check the aforementioned condition and,
if they meet the criteria, we will plop this distance into the function for the force and calculate it. Yeah, that's
the basic idea, but if we really think about it we just eliminated one-third of the whole problem, because we would
still need to iterate over **all unique pairs of atoms** in our system and calculate the distance between them **and**
check if it is smaller than $r_\textrm{cut}$. This may seem like a nitpick, but if we have a system with a large number
of particles, this operation will be very time-consuming and could be a bottleneck in our simulation.

Maybe we can use our newly introduced parameter to our advantage and limit the number of pairs we need to check? ü§î

### The art of neighborliness üèòÔ∏è

Be honest, do You care (or even know) about the neighbors one street over from Your house? Probably not, because they are
**distant** from Your perspective and **there is no interaction**. The only list of people to keep track of is of those
that actually have some, even small, influence over Your everyday life - they say "hi" to You (which is nice, I highly recommend it üëã) 
when You are taking out the trash since they can recognize You as one of their own. This catalog of people can be set up every couple of years
because people don't move that often, so it is not a big deal to keep it up to date every day.

Simple ideas but they can be applied to our system as well because any movement of particles in our system will be very small and
even if we actually **missed an opportunity** to catch some change in the local neighborhood of the chosen particle,
the error introduced by that will be very small and (in most cases) will correct itself in the next iteration. Thus, 
we can introduce a new concept of [**neighbor list** (or Verlet list)] that will contain only those particles that
are within the distance $r_\textrm{cut}$ from each other. This list will be updated every couple of iterations and
will be used to calculate the forces acting between particles.  Each atom will keep track of IDs of its closest neighbors and 
this will significantly reduce the number of pairs we need to check and will speed up our simulation.

So, since we used Jupyter Notebook to visualize the Lennard-Jones potential and force, we can also use it to
implement the neighbor list and see how it will affect the number of pairs we need to check. Let's do it!

<JupyterLiteEmbed
  size="1000px"
  file="por/neighbor_list.ipynb"
  kernel="python"
  client:load
/>

The near-100% speedup looks juicy, so we will definitely implement the lists in our simulation. But, as always, there is a catch.
The neighbor list will need to be updated every couple of iterations and this will introduce some overhead to our simulation.
This means that we will need to find a balance between the number of iterations after which we will update the neighbor list
i.e. how fast we want our subsequent calculation of forces to be and how much precision we are willing to sacrifice
and still deem our results to be physically meaningful. This is a very common trade-off in computational physics between
speed and precision. ‚öñÔ∏è

With the potential model and the neighbors list in our hands, we are ready to implement the force calculation in our simulation.
It's time to get ...

<img src="/assets/images/por_2_rusty.png" alt="Let's go!" style="margin-left:auto;margin-right:auto;height:200px;"/>

## Transcribing to crabspeak ü¶Ä

To kick things off, we will prepare a new submodule in out molecular dynamics source code, called `statics`, that will hold
all functions related to interatomic interactions and their energetics. We will try to ensure loose coupling between the
potential model interface and the rest of the simulation engine, to allow for easy swapping of potential models in the future.

So, as a little reminder, here is our current project structure:

<FileTree
  root="src/"
  tree={[
    {
      "data/": [
        "mod.rs",
        "input.rs",
        "output.rs"
      ],
    },
    {
      "system/": [
        "atom.rs",
        "box.rs",
        "cell.rs",
        "system.rs",
        "mod.rs",
      ]
    },
    "main.rs"
  ]}
  annotations={`
    data: module for handling input and output data
    system: module for handling the system of particles
  `}
  links={``}
/>

The new `statics` directory will reside parallel to other submodules and be composed of the following parts:

1. A module called `neighbours.rs` that will hold the implementation of the neighbor list.
2. A subdirectory `models` that will hold all of the implementations of all potential models that we will use in our simulations,
together with something that "glues" them together and redirects our simulation engine to the correct implementation.

["boioioioing" thing]: https://www.youtube.com/watch?v=LPaIS51XGC0
[physics-animations.com]: https://www.physics-animations.com
[literally one minute]: https://www.ucl.ac.uk/~ucfbasc/Theory/lenjon.html
[**neighbor list** (or Verlet list)]: https://en.wikipedia.org/wiki/Verlet_list
