---
title: "Particles of Rust - The Box"
date: "2024-01-11"
description: "Constructing a simulation box for molecular dynamics integrator in Rust"
tags: ["rust", "molecular dynamics", "simulation", "particles", "box"]
image:
  thumbnail: "cihero"
  hero: "cihero"
  alt: "Simulation box"
---

## The driving force üß≤

Combining the new with the familiar can be a rather hard field of mental gymnastics,
especially when dealing with abstract forms of describing our surroundings.
Have You ever seen the molecules floating around Your glass of freshly poured milk,
all entangled in the chaos of Brownian motion? What about the bytes that are pushed
through gold traces of number-crunching, silicon brains of our electronics? The existence
of these things is undeniable, but how we describe them is often conventional.
Those descriptions can be then grouped into models, that approximate the reality
while letting our minds partially wrap around the universal truths like
f!@%*ng magnets, how do they work?

So, during my years as a PhD candidate, I've been working with molecular dynamics
that are mainly based on a plethora of mathematical hallucinations, that resemble
a runic language and stick indices to every variable possible. 

I mean, just take a look at this üëá:

$$E_i = F_i(\overline{\rho}_{i}) + \frac{1}{2}\sum_{j\neq i} \phi_{ij}(\overline{r}_{ij})$$

To those not acquainted with the arcane arts, this shows the energy of an atom
interacting with its colleagues, that happens to be submerged in the cloud of electronic charge.
And that's softcore knowledge, but expressions such as this help us express the nature of
interactions of tiny weeny dots of matter that make up literally everything. History knows
dozens of models that let us calculate various properties and behavior of matter, but
the common denominator between them is that they can be boiled down to equations that
are solved numerically. These solutions can be then visualized and analyzed to basically
give us a way to peer into the world of the nanoscopic.

So, why am I rambling about this?

### Old times sake üßë‚Äçüî¨

I stopped doing my PhD a while ago because over time I've leaned more toward the
the software engineering side of things and started working as a developer, but I still
have a soft spot for this field of physics. Moreover, even the simplest simulations of
molecular dynamics can be a good project for learning a new language, due to the combination of
rational memory management, I/O operations (due to the need to read and write data)
and tricks of higher-order functions e.g. performing a reduction of a given property on a collection of
particles. This often leads to discovering some useful libraries that can be used
in other projects like linear algebra libraries and plotting tools.
Also, if You are feeling adventurous, You can try to parallelize the code
to speed up the calculations. üöÖ Everything checks out. ‚úîÔ∏è

So, that is the **familiar** thing I have decided to latch onto, no matter how exotic
it may sound. I mean, normally You would find a simpler project to start with
like some CLI tool or even the **legendary** calculator app. But I've got approximately
four years of experience in this field, so I thought it would be a good idea to
combine it with the **new** thing I'm learning, which is Rust ü¶Ä.

(Also, it's a good excuse to write about the topic I'm passionate about ü§∑)

### Extending the animal farm üê´üêçü¶Ä

In my current job, I'm working with Python and I've been doing it for a while now.
What I like about it is that it's a very expressive language i.e. has a very
low barrier to entry due to its English-like syntax and way of abstracting away
the low-level aspects of programming. There is no discussion about allocating
memory or heap/stack differences when diving into the Python language because it's all
handled by the **interpreter**. This is a double-edged sword because it makes
the language very easy to learn, but it also makes it very easy to write
inefficient code. Combine this with the fact that Python is dynamically typed
(meaning that You can ignore naming the types of data You are passing around)
and You can also wind up in a position where You have no idea what is going on
under Your program's hood.

This may sound like fear-mongering, but I've personally
written code that took forever to debug because I was writing to the same places in memory
in two, separate steps without noticing it, **especially** when working with
(honestly, pretty cool) [Python bindings for MPI], which I was using to parallelize
my calculations. Later I just decided to rewrite the code in C++. It worked like a charm.
And it was faster. Yeah, that is unfortunately the trade-off You have to make
when working with Python. It's a great language for prototyping, but when it comes
to performance, there are better options. When I was running calculations for systems
that were composed of like 2000 objects - it was fine, the CPU and RAM usage was
fine and dandy. But throwing millions of atoms into my numerical grinder,
stopped it dead in its tracks. One time I was even notified by the administrator
of the supercomputer I was using that my job was taking too much memory and
was promptly terminated. üòÖ With C++, the problem was gone, because I could
declaratively say to the compiler that I wanted to allocate a certain amount of memory,
do some magic tricks on it and then set it free.

As I said, Python is really competent when it comes to building software not-so-concerned
with squeezing every last clock cycle out of the CPU and when You want to run Your
tested application fast like immediately after making new changes. C++ (and Rust) are
compiled languages, so the development experience is significantly different.
The testing itself requires a bit more effort due to compilation time being added to
each run. Also - and that is a very opinionated statement - I think that Python
is king when it comes to data science **in practice** due to its ecosystem of libraries
and solutions like Jupyter Notebooks. So, I am not ditching Python - it is good.

But I want to learn something new and Rust is a language that I've been eyeing for
a while now. It's compiled and has a very strong type system, which means that
the compiler will not let You do stupid things like unsafe memory access.
The borrowing system is also a very interesting concept to me and it seems to resonate
with me. And, from looking at the open-source projects written in Rust, it seemed
to have a very expressive syntax. So, I decided to give it a try.
The atoms will speak in crab tongue today. ü¶Ä

## Playing safe

The molecular simulation engine is nothing more than a numerical integrator that enforces
some additional conditions like the conservation of energy.
The amount of equations and descriptions of interactions between atoms with
aforementioned constraints is **huge**, literally dozens of monstrous textbooks have been written on the subject.

So, a Minimal Viable Product (MVP) for this project would be a simulation of a system
composed of single-type atoms that interact with each other via a model described
by simple mathematical function dependent **only** on the distance between them.

Simulations will be configured via scripts that will have pre-defined syntax and will be
parsed by the program. The output of the simulations will contain quantities chosen by the user
like the energy of the system, the temperature, the pressure, etc. and could be written to
either a file or the standard output.

I will start with a simple pair of atoms and then see how it works for a known atomic structure.
In both cases, geometry will be defined by two objects: the simulation box (the space occupied by the entire system)
and a unit cell - a repeating pattern of atoms that will be used to construct the simulation box.

So, a user will define the shape of a unit cell and the number of repetitions in each direction.
The simulation box will be constructed by repeating the unit cell in each direction.

So the general simulation workflow will look like this:

1. Read the configuration file
2. Construct the simulation box with atoms
3. Calculate the forces between atoms
4. Integrate the equations of motion
5. Write the output
6. Repeat steps 3-5

And so on, until a certain condition is met - for example, the simulation time is up.

In this article, I will focus mainly on the first two steps, since the actual physics
of such atomic systems deserves a separate blog post due to the complexity of the subject.
Moreover, this part is a good introduction to the very basics of Rust such as
simple data structures, file I/O and error handling.

Moreover, I will try to point out specific aspects of Rust
I've learned along the way and explain them in a way that will be understandable
to people that are not familiar with the language.

So, let's get to it!

## Defining the minuscule

Before we begin to define each setting of the simulation, a general format has to be chosen.
Here, we can try to reinvent the wheel and cook up some arbitrary syntax that will require an
additional parser (on top of methods that will spawn new entities from the settings) or
choose one of the standards that have stood the test of time.

So, I've chosen YAML as my base for simulation configs, due to its simplicity and
the fact that I don't expect a lot of nesting to be happening in the settings.
Also, Rust has a very good YAML crate (library) called `rust_yaml`, so it's a win-win.

The simulation script will be divided into thematic sections, each containing
a list of settings:

<CodeSnippet
  code={`
    system:
      ...
    neighbours:
      ...
    potential:
      ...
    dynamics:
      ...
    thermodynamics:
      ...
    logger:
      ...
  `}
  language="yaml"
  filename="input.yaml"
  annotations={`
    1: Definition of the geometry of the system.
    3: Settings for constructing the list of atoms that are close enough to interact with each other.
    5: Definition of the parameters for functions that describe interactions between atoms.
    7: Settings for the equations of motion integration.
    9: Thermodynamic description of the system i.e. if it should be kept at a constant temperature or pressure.
    11: Simulation output settings - what and where should be written.
  `}
/>

To utilize this script we will need some kind of parser that will read the file and
spawn the appropriate objects. Here we can see the first functionality that can be
isolated into a sort of submodule - the one concerned with loading and saving data.

#### Particle No. 1 - Organization through isolation üèùÔ∏è

So, a first lesson in Rust - how to structure the code. From what I've gathered, there are
two ways to ship code in Rust - either as a library or as a binary. The library is for
latching Your code onto other projects, while binary acts as a standalone application.
These shipments are called **crates** and they are defined by a `Cargo.toml` file, which name
comes from the CLI tool that is a standard way to manage dependencies in Rust - `cargo`.
In our case, this file will be very, very simple:

<CodeSnippet
  code={`
    [package]
    name = "rustomics"
    version = "0.1.0"
    edition = "2024"

    [dependencies]
    yaml-rust = "0.4.5"
  `}
  language="toml"
  filename="Cargo.toml"
  annotations={`
    1: Basic information about the crate.
    2: Cute portmanteau of Rust and molecular dynamics. ‚öõÔ∏èü¶Ä
    7: Look, our first dependency!
  `}
/>

Having this file in the root directory of our project, we can now create a directory
that contains the source code of our crate. It will be called `src` and will contain
a file called `main.rs` that will be the entry point of our application. The name
of this file is dependent on the type of crate we are building - if it's a library,
it will be called `lib.rs`.

Inside this wile, just like in C/C++, a main routine called `main` will be defined:

<CodeSnippet
  code={`
    // Here we will import the main submodules

    fn main() {
      ...
      // Here we will load the configuration file
      // and start the simulation
    }
  `}
  language="rust"
  filename="main.rs"
  annotations={`
    3: The entrypoint of our binary
  `}
/>

As said previously, I want my file-parsing functionality to be isolated from the rest
of the code, so I will create an `io` directory, that will contain a file called `mod.rs`.
This file also serves as an entry point for the other parts of the code, that can group
several `.rs` files into a single **namespace**. We will then be able to use any elements
from this namespace by using the `io` prefix, e.g. `io::load_config()` or something like that.
For now, I will separate the input from the output, so I will create two files named just like that:
`input.rs` and `output.rs`. The `mod.rs` file will look like this:

<CodeSnippet
  code={`
    pub mod input;
    pub mod output;
  `}
  language="rust"
  filename="io/mod.rs"
  annotations={`
    1: Importing the input submodule
    2: Importing the output submodule
  `}
/>

The `pub` keyword is used to make the module public, so it can be used outside of the `io` namespace.
There is some usability to functions that can be only accessed in the scope of a single namespace,
like operations that don't have a practical meaning outside of the context of a given submodule.

An example of that would be a function that reads a single line from a file - it's not really
useful outside of the context of parsing a file, so it can be private. This function then can be
used by some other function within that same namespace e.g. called `load_file` that will be public and
iterate over freshly read lines. This way we can hide the implementation details of the function or
a group of functions and expose only the ones that are useful to the user.

In the beginning, we will make everything public and then think if any information hiding is necessary -
it is the least of our concerns right now. After this preparation, our `src` directory structure will look like this:

<FileTree
  root="src/"
  tree={[
    {
      "data/": [
        "mod.rs",
        "input.rs",
        "output.rs"
      ],
    },
    "main.rs"
  ]}
  annotations={``}
  links={``}
/>

#### Particle No. 2 - Learning to expect

The `input.rs` file will contain the code that opens and
reads our YAML configuration and contains some helpers to deserialize the data into the appropriate
data structures. We will ignore `output.rs` for now - it will make a comeback when we define our logging logic later.

<CodeSnippet
  code={`
    use std::fs::read_to_string;
    use yaml_rust::Yaml;

    pub fn parse_yaml(filepath: &str) -> yaml_rust::Yaml {
        let script_file = read_to_string(&filepath).expect("Failed to read script file");
        let script_yaml =
            yaml_rust::YamlLoader::load_from_str(&script_file).expect("Failed to parse script file");
        script_yaml[0].clone()
    }
  `}
  language="rust"
  filename="io/input.rs"
  annotations={`
    2: Here we import a specific structure from rust_yaml library
    4: This function will read the file and parse it into a YAML structure
    5: We try reading from the file and if it fails, we panic with a custom message
    6: We try parsing the file and if it fails, we panic with a custom message
    7: We return the first element of the read YAML files, so our simulation config
  `}
/>

In Rust, we can control the flow of the program by using the `match` keyword, which
acts like a `switch` statement seen in other programming languages **BUT** it has
one useful rule baked into it - it has to be exhaustive. This means that we have to
cover all possibilities i.e. branches of our operation.

<CodeSnippet
  code={`
    let a = 5;
    match a {
      1 => println!("One"),
      2 => println!("Two"),
      _ => println!("Something else"),
    }
  `}
  language="rust"
  filename="Example of a match statement in Rust"
  annotations={`
    1: We define a variable
    3: If the value is equal to 1, we print "One"
    4: If the value is equal to 2, we print "Two"
    5: If the value is equal to anything else, we print "Something else"
  `}
/>

In the example above, we can see that the `_` symbol is used to denote the default case
or what happens if all cases above it are not satisfied (there is no **match**). So for our `a = 5`,
the output would be `Something else`. What is **super** useful about this branching out logic
is that it can also be used to conditionally assign values to variables:

<CodeSnippet
  code={`
    let a = 5;
    let b = match a {
      1 => "One",
      2 => "Two",
      _ => "Something else",
    }
  `}
  language="rust"
  filename="Assigning match to a variable"
  annotations={`
    1: We define a variable
    2: We define another variable and assign it a value based on the value of the first variable
  `}
/>

But we can go even further. In Rust, there is a type of data called `Option` that symbolizes
that a variable can hold a member of a given type e.g. an integer or nothing at all.
So, **Some**thing or **None** at all. Imagine an operation that may return a value or,
in case of an exception, throw out **None**, which is often done to not halt the execution
of a program and let the code handle that case somewhere else. In Rust, we can use the `match`
statement to handle these conditions:

<CodeSnippet
  code={`
    fn operation(a: i64) -> Option<f64> {
      match a {
        0 => None,
        _ => Some(a as f64 / 100.0),
      }
    }

    fn main() {
      let b = match operation(5) {
        Some(i) => i,
        None => 0.0,
      };
      println!("{}", b)
    }
  `}
  language="rust"
  filename="Matching an Option type"
  annotations={`
    1: We define a function that takes an integer and returns an Option type
    2: We match the value of the integer
    3: If the value is equal to 0, we return None
    4: If the value is equal to anything else, we return Some with the value of the integer divided by 100
    8: We define a variable that will hold the result of a match done on the operation result
    10: If the result is Some, we assign the value to the variable
    11: If the result is None, we assign 0.0 to the variable
    12: We print the value of the variable
  `}
/>

Here, a quick note: the `println!` takes a string as an argument and then replaces
each consecutive `{}` with the value of the variable passed after the string, in the order
of appearance. So, in this case, the output will be `0.05`. Okay, back to the topic.

A very simple pattern emerges: if *something on left happens* `=>` *return a specific value*.
Here it should be noted that multiple patterns can be matched to a single value:

<CodeSnippet
  code={`
    let a = 5;
    match a {
      1 | 2 => println!("One or two"),
      _ => println!("Something else"),
    }
  `}
  language="rust"
  filename="Matching multiple patterns"
  annotations={`
    1: We define a variable
    3: If the value is equal to 1 or 2, we print "One or two"
    4: If the value is equal to anything else, we print "Something else"
  `}
/>

Moreover, if we want multiple cases to return `None`, we are free to do so,
there is no restriction on that - just plop them down on the right side of chosen branches.

But, in practice, writing one `match` statement after another can be very tedious,
**especially** where there are only two branches - all or nothing.
So, Rust has two useful methods specific to the `Option` type - `unwrap` and `expect`.

The first one will return the value of the `Some` branch or panic if the value is `None`.
The second one is a slight variation of an `unwrap` operation, but it allows us to specify a custom
message that will be printed in case of a panic.

In short, if we want to handle the **None** cases in a very specific way, we can use `match`
and bake that logic right after appropriate `=>`'s. If we only case that the operation
succeeds and any `None` value is not to be tolerated, we throw up our hands
and use `unwrap` or `expect` (depending if we want to tell our user what happened).

So, our `parse_yaml` function utilizes that - it tries to read the file and if it fails,
it panics with a custom message. Then it tries to parse the file and if it fails, it panics
with a custom message. If everything goes well, the final **Some**thing, containing our parsed script
is returned.

#### Particle No. 3 - Wait, what's &? ü§î

If You are observant enough, You may have noticed that the `parse_yaml` function takes
one argument, that has a type prepended with an ampersand (`&`). In this context,
it is a reference to an array of characters in our computer's memory, so a pointer to
some string or a slice of a string (substring). So, why not just pass the string itself?

Here, we arrive at the borrowing mechanism of Rust and the lifecycle of variables defined
in our code. Imaging that every pair of curly braces in Rust serves as a separated **context** (scope)
that functions on its own and has an isolated portion of data it can modify and use.
Things defined within that context lose their meaning after exiting its boundaries.

You can imagine that as groups of people that are having a conversation about totally
different topics. Over the course of their conversations, some specific situational jokes
or expressions pop up, that are only understood by the people that were present in that group.
When the conversation stops and participants try to use the same joke in another group, they will
be met with blank stares and awkward silence. üòÖ They simply don't know what is being talked about,
since **the context has vanished**.

So, in Rust, this manifests as variables whose lifetimes are limited to certain scopes of code
enclosed between curly brace - simple as that:

<CodeSnippet
  code={`
    fn main() {
      let a = 5;
      {
        let b = 10;
        println!("{}", a + b);
      }
      println!("{}", a + b);
    }
  `}
  language="rust"
  filename="Variable lifetimes in Rust"
  annotations={`
    2: We define a variable
    3: We enter a new context
    4: We define a variable
    5: We print the sum of a and b
    6: We exit the context
    7: We try to print the sum of a and b, but b is not defined in this context
  `}
/>

The second print statement will fail to compile since the variable `b` is, well, gone -
it has vanished together with the completion of the previous code block. However, the variable `a`
can be printed in this nested context, since the `main` function serves as a **global** context
from the point of view of the one with `b` variable defined. So, a hierarchy of contexts is formed
that can be utilized to keep some data persistent (`a`) and some data temporary (`b`).

So, what does it have to do with the `&` symbol? Well, when we pass a variable to a function,
we can either pass it by value or by reference. In Rust, passing by value means that the variable
is basically **given away** to the new code block and **its lifetime** is shortened to the scope
of its new **owner**. This means that the variable cannot be used in the previous context anymore,
which can be checked via this simple code:

<CodeSnippet
  code={`
    fn main() {
      let a = 5;
      println!("{}", a);
      take_ownership(a);
      println!("{}", a);
    }

    fn take_ownership(a: i64) {
      println!("{}", a);
    }
  `}
  language="rust"
  filename="Passing by value"
  annotations={`
    2: We define a variable
    3: We print the value of the variable
    4: We pass the variable to a function
    5: We try to print the value of the variable, but it IS DEAD üíÄ
  `}
/>

The second print statement will fail to compile since the variable `a` went down with the ship
named `take_ownership`. So, how do we pass a variable without giving it away? We pass it by reference.
A reference is **an address** of a variable in memory, so **a pointer** to a given location in memory.

<CodeSnippet
  code={`
    fn main() {
      let a = 5;
      println!("{}", a);
      take_reference(&a);
      println!("{}", a);
    }

    fn take_reference(a: &i64) {
      println!("{}", a);
    }
  `}
  language="rust"
  filename="Passing by reference"
  annotations={`
    2: We define a variable
    3: We print the value of the variable
    4: We pass the variable to a function
    5: We try to print the value of the variable and it's still alive and well
  `}
/>

Now, the variable `a` is still alive and well, since it was only **borrowed** by the function.
That is how Rust handles data that may be dangling around our program - it simply doesn't allow it.
After the context where the variable basically makes sense is gone, the data is swiped from the memory
since it has **contextually** no use in further execution of the program. 

**So, passing by value is akin to situational jokes and borrowing is like a meme - it can be referenced in multiple places
and it will still (hopefully) be understood.** Take it or leave it. ü§∑

So cool, we can pass data around, but what about modifying it? Well, we can't do that either without
stating it **explicitly** to Rust. This is done by using the `mut` keyword, which is short for **mutable**.
If we prepend out variable or parameter type by this keyword, we can modify it in the context of the function
and those changes will be permanent. So, if we want to modify the value of `a` in the `take_reference` function,
we have to do it like this:

<CodeSnippet
  code={`
    fn main() {
      let mut a = 5;
      println!("{}", a);
      take_reference(&mut a);
      println!("{}", a);
    }

    fn take_reference(a: &mut i64) {
      *a += 5;
    }
  `}
  language="rust"
  filename="Passing by mutable reference"
  annotations={`
    8: Here we point to the location of "a" in memory and say its okay to modify it
    9: We modify the value of the variable
  `}
/>

To modify `a`, we must remember to dereference it by using the `*` symbol, since we want
to access the value of the variable, not the address of it. So this little asterisk means
*whatever is under that address*. What if we try to use the dereference on a normal variable?
Rust will politely ask us what are we doing. It will also warn us if we borrow the same variable
twice under the same context since that would mean **modifying the same data in two places**.
That's **borrowing checker** in action - it will not let us do stupid things. And if You remember,
it is one of the reasons why I decided to learn Rust. üëÜ

#### Particle No. 4 - Modeling the simulation üìê

Going back to the theme of nicely packing things into isolated entities, we have to think about
shaping our simulation environment. We know that, apart from the simulation box geometry,
we will use other components such as a numerical integrator, a logging system, etc.

So, a class? Well, Rust handles things differently when it comes to "objectifying" Your data.
First of all, no inheritance, subtypes, polymorphism, etc. - it's all gone. ü§Ø
We are left with simple data aggregates that can be passed around and modified.
The common behavior of these structures is defined by **traits** - a concept similar to
interface, so a group of functions is implemented by a given type.

So the first aggregate used in my code will be a `struct` i.e. a container of data that
will hold the simulation state and progress the internal time clock to predict new
positions of atoms etc. This structure will be called `Simulation` and will contain
the following fields:

<CodeSnippet
  code={`
    pub struct Simulation {
      pub system: SystemDefinition,
      pub integrator: DynamicsIntegrator,
      pub clock: InternalClock,
      pub potential_model: PotentialModel,
      pub neighbours: NeighboursList,
      pub energetics: SystemEnergetics,
      pub thermodynamics: Thermodynamics,
    }
  `}
  language="rust"
  filename="simulation.rs (Simulation)"
  annotations={`
    2: A structure that will hold the information about the system geometry.
    3: Settings for the equations of motion integration.
    4: A structure that will hold the information about the internal clock of the simulation.
    5: A structure that will hold an initialized model of interactions between atoms.
    6: A structure that will hold the information about the list of atoms that are close enough to interact with each other.
    7: A structure that will hold the information about the energetics of the system.
    8: A structure that will hold the information about the thermodynamics of the system.
  `}
/>

As You can see, structures can be nested and throughout this and future articles we will
be implementing each of those components in batches. Additionally, this structure corresponds
to fields defined previously in our YAML script so they can be configured by each section
of the configuration file separately.

To show how the implementation of structure interfaces in Rust works, I will briefly focus on
the `InternalClock` field, since it will be a very simple component to code and is a good
starting point for learning the basics of the Rust object model.

#### Particle No. 5 - structure of time ‚è∞

So, the `InternalClock` structure will be responsible for keeping track of the simulation time.
The numerical integrator will use **time steps**, so a small increments of time that will be
used to calculate the new positions of atoms. The clock will have to keep track of the current
time and the number of current subtypes. These values will be checked against the settings passed
by the used about the maximum simulation time to be run - since this will be out condition
for stopping the execution of our program.

<CodeSnippet
  code={`
    pub struct InternalClock {
        // Definition of the simulation length and time step
        pub timestep: f64,
        pub total_time: f64,
        // Runtime variables i.e. rolling time and step
        pub current_step: u64,
        pub current_time: f64,
    }
  `}
  language="rust"
  filename="simulation.rs (InternalClock)"
  annotations={`
    7: This value is basically: (current_time * timestep)
  `}
/>

A clock ticks. In our case, we can say it is more of a stopwatch - it start at zero, keeps ticking
and can be conditionally stopped or reset. Those three characteristics are basics on **impl**ementation
for out `InternalClock` structure. Rust lets us latch onto a structure and define its behavior
by using the `impl` keyword. This way we can define functions that will be associated with
our clock that can modify its internal state. Additionally, we can define a default way of
creating a new instance of our structure by using the `new` function. Combining this all together,
we can get the following implementation:

<CodeSnippet
  code={`
    pub struct InternalClock {
        // Definition of the simulation length and time step
        pub timestep: f64,
        pub total_time: f64,

        // Runtime variables i.e. rolling time and step
        pub current_step: u64,
        pub current_time: f64,
    }

    impl InternalClock {
        pub fn new(timestep: f64, total_time: f64) -> InternalClock {
            InternalClock {
                current_step: 1,
                current_time: 0.0,
                timestep: timestep,
                total_time: total_time,
            }
        }
        pub fn tick(&mut self) -> () {
            self.current_step += 1;
            self.current_time += self.timestep;
        }
        pub fn reset(&mut self) -> () {
            self.current_step = 1;
            self.current_time = 0.0;
        }
        pub fn has_finished(&self) -> bool {
            self.current_time >= self.total_time
        }
    }
  `}
  language="rust"
  filename="simulation.rs (InternalClock + impl)"
  annotations={`
    11: We say that we will IMPLEMENT the behavior of the InternalClock structure
    12: We pass by value, since we don't care about this data after the function is done
    13-18: New instances of the clock will be set to the initial state (so no time passed yet)
    20: This function will increment the internal time and step
    21-22: We can modify data in the InternalClock because we use the &mut keyword
    24: This function will reset the internal time and step to "zeros"
    28: This function will check if the simulation has finished
  `}
/>

We can use the same logic of implementing state and behavior for other structures - namely our `Simulation` object.

<CodeSnippet
  code={`
    pub struct Simulation {
        ...
        pub clock: InternalClock,
        ...
    }

    impl Simulation {
        pub fn from(yaml: &yaml_rust::Yaml) -> Simulation {
            let timestep = dynamics_setup["timestep"].as_f64().unwrap();
            let calculated_total_time = match &dynamics_setup["total_time"] {
                Yaml::Real(x) => x.parse::<f64>().unwrap(),
                Yaml::BadValue => dynamics_setup["steps"].as_i64().unwrap() as f64 * timestep,
                _ => dynamics_setup["steps"].as_i64().unwrap() as f64 * timestep,
            };

            Simulation {
                ...
                clock: InternalClock::new(timestep, calculated_total_time),
                ...
            }
        }
    }
  `}
  language="rust"
  filename="simulation.rs (Simulation + impl)"
  annotations={`
    2-8: For now we will omit initializing the other fields, for demonstration purposes
    10: CAVEAT - match statement requires us to borrow the tested value ‚ùó
    11: The "parse" method comes from "rust_yaml" library, specific to YAML string field
    12: The "as_[type]" methods are used to cast the value to a given type
    13: Similarly, we can cast a whole expression by adding the "as [type]" to the end
  `}
/>

As seen in line 18, object-specific methods can be called by using the `::` operator,
similar to accessing methods defined for a namespace. Knowing how to create and modify
our structures, we can now move on to the next steps - defining our atomic structures and 
enclosing them in the simulation box.

### Building with rods and spheres

Similar to our previous considerations, it is useful to establish some sort of model
that we will base our new structure in code upon. We know that the simulated system
will be composed of singular atoms occupying a 3D space, defined by a simulation box.
To keep our code tidy, we will separate implementation of this system into a submodule
called, well, `system`. So, similar to the `io` directory, it will have a `mod.rs` file
and other source code separated into files named after the structures they define:

<FileTree
  root="src/system"
  tree={[
    "atom.rs",
    "box.rs",
    "cell.rs",
    "system.rs",
    "mod.rs",
  ]}
  annotations={`
    atom.rs: Definition of the atom structure.
    box.rs: Definition of the simulation box structure.
    cell.rs: Definition of the unit cell structure.
    system.rs: Definition of the system structure.
    mod.rs: Here we import he above structures.
  `}
  links={``}
/>

The simplest structure to define is the `Atom` structure since it is easily defined
from the physics point-of-view in the context of our simulation. So, without further ado:

<CodeSnippet
  code={`
    pub struct Atom {
        pub id: u64,
        pub name: String,
        pub previous: PreviousState,
        pub current: CurrentState,
        pub mass: f64,
        pub charge: f64,
    }

    impl Atom {
        pub fn new() -> Atom {
            Atom {
                id: 0,
                previous: PreviousState {
                  ...
                },
                current: CurrentState {
                  ...
                },
                mass: 1.0,
                charge: 0.0,
                name: String::from("NaN"),
            }
        }
    }
  `}
  language="rust"
  filename="system/atom.rs"
  annotations={`
  `}
/>

A slight surprise is the `PreviousState` and `CurrentState` fields. Physics likes differences and changes,
especially when it comes to numerical models and calculating properties of matter. So, we will need
to keep track of the previous state of the atom, so we can calculate the difference between the current
and the previous state. As You will see in later articles, it will have a very practical use during
solving the equations of motion. They both will have the same fields i.e. they will only differ
in name:

<CodeSnippet
  code={`
    use nalgebra::Vector3;

    pub struct CurrentState {
        pub position: Vector3<f64>,
        pub velocity: Vector3<f64>,
        pub force: Vector3<f64>,
        pub potential_energy: f64,
        pub kinetic_energy: f64,
        pub total_energy: f64,
    }

    pub struct PreviousState {
        pub position: Vector3<f64>,
        pub velocity: Vector3<f64>,
        pub force: Vector3<f64>,
        pub potential_energy: f64,
        pub kinetic_energy: f64,
        pub total_energy: f64,
    }
  `}
  language="rust"
  filename="system/atom.rs (states)"
  annotations={`
    1: Wait, what? üòü
    2-7: The current state of the atom.
    11-16: The previous state of the atom.
  `}
/>

And here, I have a confession to make, but it will serve as a segway into the memory heap and stack
utilization in Rust.

#### Particle No. 6 - I have inverted matrices You wouldn't believe ü§ñ

First of all - heap and stack. This is one of the ultimate classics of computer science, explained
**a plethora** of times from within old walls of universities to random videos on YouTube. We will
go over this quickly, from the point of view of Rust compiler.

In some parts of the code, You can explicitly say that You will crunch a specific amount of values
within a function. For example, a sum of two numbers will **always** need two spaces in memory
to store the `a` and the `b` that will return `a+b`. Moreover (especially in Rust) You can say
**of which type** those values will be. So, if we want to sum two integers, we will need two
spaces in memory that will hold two integers. All of this is known, so the compiler during the translation
of our code to the magical dialect of 1's and 0's can say to our operating system to reserve
a **specific amount of memory** for **known amount of time** (or for a given scope).

For such tasks, a stack is used - a part of memory that is used to store data that has a specific
size and place in the code, so a system can manage it easily. This is called **stack allocation**.

An example of such data structure in Rust is **an array** - a collection of values of the same type
that has a specific size. So, if we want to store 10 values of `i64` type, we can do it like this:

<CodeSnippet
  code={`
    let a: [i64; 3] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];
  `}
  language="rust"
  filename="Stack allocation"
  annotations={`
    1: Note the type annotation - [type; size]
  `}
/>

This is **set in stone** ü™¶. No matter what user will give as an input, `a` will always be
10 integers (of 64 bits each), in a row. But what about situations where the amount of data
will vary? For example, we want to store a list of atoms, but we don't know how many of them
will be in the system **at compile time**. A user should be able to define the number of atoms,
so a normal array will not do. We need something that can **grow** and **shrink**.

This is where the heap comes in. It is a part of memory that is used to store data that has
a **dynamic size**. This is called **heap allocation**. In Rust, this is done by using the `Vec`
structure, which is a **vector** - a collection of values of the same type that can grow and shrink.

<CodeSnippet
  code={`
    let a: Vec<i64> = Vec::new();

    ... // Let's pretend the user gives us here
        // the number of values to push into our Vec

    for i in 0..user_input {
      a.push(i);
    }
    
    println!("{:?}", a);
  `}
  language="rust"
  filename="Heap allocation"
  annotations={`
    1: Note the type annotation - Vec<type>
    6-8: We keep pushing values to the vector
  `}
/>

The `push`'ing into a vector dynamically allocates new memory for the new value and copies
the number into that place. This is **slower** than stack allocation, because the system
has to actively look for a place to put the new value and copy it there. But, it is **more flexible**.

Here's a tradeoff - if we know the size of the data we want to store, we can use stack allocation
and get a **faster** code. If we don't know the size of the data we want to store, we can use heap allocation
and get a **more flexible** code.

Nice, so what is the `Vector3` structure I am using for my `Atom` fields? Well, it is a vector
that has a **static size** of 3 and is **stack allocated**. Why not use a normal array then?
Because of linear algebra. ü§∑ The `nalgebra` crate basically implements a lot of useful
operations of vectors and matrices, so we can use them in our code, but under the hood,
[they are still arrays with sizes known at compile time]. So, things like dot product, cross product
or inverting matrices are already implemented for us **efficiently** and one of the things I have learned
during my PhD is this:

<img src="/assets/images/dontneedalgebra.png" alt="Independent" style="margin-top:1rem;margin-bottom:1rem;" height="500" />

The only exceptions are when **there is no linear algebra library for the language** or
**the library is a slow-as-heck abandonware**. In other cases, just **use established tools**.
Or at least something that was used by at least 10 people, so You will not feel stupid alone
if something goes wrong over time. üòÖ

In short, `Vector3<f64>` is basically a `[f64; 3]` array with linear algebra operations latched onto it.
The `Matrix3<f64>`, which You will see in a second, is a counterpart of `[[f64; 3]; 3]` on steroids.
And everything is stack-allocated, so it's fast. üöÄ

#### Implementing Atom 2: Atomic Boogaloo

Okay, now we can complete the `new` method of the `Atom` structure, defined previously in the `atom.rs` file:

<CodeSnippet
  code={`
    use nalgebra::Vector3;

    pub struct CurrentState {
        pub position: Vector3<f64>,
        pub velocity: Vector3<f64>,
        pub force: Vector3<f64>,
        pub potential_energy: f64,
        pub kinetic_energy: f64,
        pub total_energy: f64,
    }

    pub struct PreviousState {
        pub position: Vector3<f64>,
        pub velocity: Vector3<f64>,
        pub force: Vector3<f64>,
        pub potential_energy: f64,
        pub kinetic_energy: f64,
        pub total_energy: f64,
    }

    pub struct Atom {
        pub id: u64,
        pub name: String,
        pub previous: PreviousState,
        pub current: CurrentState,
        pub mass: f64,
        pub charge: f64,
    }

    impl Atom {
        pub fn new() -> Atom {
            Atom {
                id: 0,
                previous: PreviousState {
                    position: Vector3::zeros(),
                    velocity: Vector3::zeros(),
                    force: Vector3::zeros(),
                    potential_energy: 0.0,
                    kinetic_energy: 0.0,
                    total_energy: 0.0,
                },
                current: CurrentState {
                    position: Vector3::zeros(),
                    velocity: Vector3::zeros(),
                    force: Vector3::zeros(),
                    potential_energy: 0.0,
                    kinetic_energy: 0.0,
                    total_energy: 0.0,
                },
                mass: 1.0,
                charge: 0.0,
                name: String::from("NaN"),
            }
        }
    }
  `}
  language="rust"
  filename="system/atom.rs (with states added)"
  annotations={`
    35-40: We can use the "zeros" method to initialize the vectors with zeros! üò∏
  `}
/>

The last big question left for the `Atom` structure is how to initialize it with data?
We can do it by using the `from` method, which will take a YAML structure and return
a new instance of the `Atom` structure. This way, we can initialize the `Atom` structure
with data from the YAML script e.g. by defining each particle as a separate entry.
In the script, this information will be held under `atoms` subsection of `system` settings, like so:

<CodeSnippet
  code={`
    system:
      atoms:
        - name: "Al"
          position: [0, 0, 0]
        - name: "Al"
          position: [0, 0.5, 0.5]
    ...
  `}
  language="yaml"
  filename="Example of atoms definition in YAML"
  annotations={`
    3: We define the name of the atom
    4: We define the position of the atom
  `}
/>

Here, we can see that we have two atoms defined, both of them are aluminum atoms. Our simulation engine
will allow user to define atoms by their name, so we can have multiple types of atoms in the system.
If the name corresponds to an actual element, the mass and charge of the atom will be automatically
assigned to the atom from the periodic table, thanks to a library called `periodic_table_on_enum.
After that, three quantities connected to the atom **state** will be able to be defined by the user:

- (required) `position` - the position of the atom in the simulation box, expressed in **relative** coordinates, so
  from 0 to 1 in each dimension of the simulation box (e.g. 0.5 means the middle of the box edge)
- (optional) `velocity` - the velocity of the atom
- (optional) `force` - the force acting on the atom

All three of those properties are vectors, so they will be defined as such in the YAML script (as YAML arrays).
Of course, the user can define custom particles, but the `charge` and `mass` fields will have to be defined manually.
When it comes to YAML arrays, we first have to convert it to a Rust array (`[f64; 3]`) and then to a `Vector3<f64>`.
To do so, we will define two helper functions in the `io/input.rs` file.

<CodeSnippet
  code={`
    use nalgebra::Vector3;

    pub fn to_vec_f64<const SIZE: usize>(yaml: &yaml_rust::Yaml) -> [f64; SIZE] {
        let vectorized_yaml_entry: &Vec<Yaml> = yaml.as_vec().unwrap();
        if vectorized_yaml_entry.len() != SIZE {
            panic!(
                "Expected {} elements, found {}",
                SIZE,
                vectorized_yaml_entry.len()
            );
        }
        vectorized_yaml_entry
            .iter()
            .map(|x| match x {
                Yaml::Real(x) => x.parse::<f64>().unwrap(),
                Yaml::String(x) => x.parse::<f64>().unwrap(),
                Yaml::Integer(x) => *x as f64,
                _ => panic!("Unknown type"),
            })
            .collect::<Vec<f64>>()
            .try_into()
            .expect("Failed to convert to array")
    }

    pub fn to_vec3(yaml: &yaml_rust::Yaml) -> Vector3<f64> {
        let vectorized_yaml_entry: [f64; 3] = to_vec_f64::<3>(&yaml);
        Vector3::from(vectorized_yaml_entry)
    }
  `}
  language="rust"
  filename="io/input.rs (vector serializers)"
  annotations={`
    3: This function will convert a YAML array to a Rust array of a given size
  `}
/>

The most crucial is the `to_vec_f64` method since it will effectively deserialize information
from YAML script, which at the beginning is held in the form of a `Yaml::Array` type. Here, we use
[generic parameter] called `SIZE`, which will tell the compiler the expected size of the array
constructed by the function. This way, we can use this function to convert YAML arrays of different
sizes to Rust arrays of different sizes by compiling and using different versions of the function.

This generic parameter is enclosed in the `<>` brackets with an additional `const` keyword,
which means that the value of the parameter will be known at compile time.
Invoking this generic function will look like this:

<CodeSnippet
  code={`
    let a: [f64; 3] = to_vec_f64::<3>(&yaml);
  `}
  language="rust"
  filename="Invoking the to_vec_f64 function"
  annotations={`
    1: We define a variable that will hold the result of the function
    2: We invoke the function with the generic parameter set to 3
    3: We pass the YAML array to the function
  `}
/>

We must keep attention to the fact that we are constantly **borrowing** the YAML array
because we will 100% read its contents in other parts of our simulation initialization procedure.
If we passed it by value, then after `to_vec_f64` function is done, the YAML array would
be destroyed. üòû

The next interesting part of the `to_vec_f64` function is the chain of operations that
occurs after paring the YAML array.

#### Particle No. 7 - Down the crabby hole ü¶Ä

When we look at the lines after the `if` statement in the `to_vec_f64` function, we can see
a chain of operations that are connected by the `.` operator. This is called **method chaining**
and is a very common pattern in Rust. It is used to **chain** multiple operations on a given object
and return the result of the last operation.

The `vectorized_yaml_entry` is basically a vector of separate references to YAML entries (values) that are
to be iterated and parsed individually. Key word here - **references**, it will come in handy in a second.
So, the overall procedure will look like this:

1. We iterate over the vector of YAML entries
2. For each entry, we check its type:
  * If it is a `Yaml::Real` (a stringified real number), we parse it as a `f64` and push it to a new vector
  * If it is a `Yaml::String` (a string), we parse it as a `f64` and push it to a new vector
  * If it is a `Yaml::Integer` (an integer), we parse it as a `f64` (**after dereferencing the pointer** üëâ) and push it to a new vector
  * If it is anything else, we panic, the YAML is invalid
3. We collect the all parsed `f64` values into a single vector
4. We try to convert the vector into a Rust array of a given size

If everything goes well, we will get a Rust array of a given size, filled with parsed values.
In other cases, we panic with explicit messages.

Each entry in the list above can be translated to operators, that are to be chained **one after another**,
resulting in the nice, readable flow of data. This is the second reason why I decided to learn Rust - the way
in which workflows are presented in the source code is really nice and easy to follow. üòç

So, our code snippet can be presented like this, to home in on this pattern:

<CodeSnippet
  code={`
    ...
    vectorized_yaml_entry
        // 1. We iterate over the vector of YAML entries
        .iter()
        // 2. For each entry, we check its type:
        .map(|x| match x {
            // If it is a Yaml::Real (a stringified real number),
            // we parse it as a f64 and push it to a new vector
            Yaml::Real(x) => x.parse::<f64>().unwrap(),
            // If it is a Yaml::String (a string),
            // we parse it as a f64 and push it to a new vector
            Yaml::String(x) => x.parse::<f64>().unwrap(),
            // If it is a Yaml::Integer (an integer),
            // we parse it as a f64 (after dereferencing the pointer) and push it to a new vector
            Yaml::Integer(x) => *x as f64,
            // If it is anything else, we panic, the YAML is invalid
            _ => panic!("Unknown type"),
        })
        // 3. We collect the all parsed f64 values into a single vector
        .collect::<Vec<f64>>()
        // 4. We try to convert the vector into a Rust array of a given size
        .try_into()
        .expect("Failed to convert to array") // Here the exception is handled
  `}
  language="rust"
  filename="io/input.rs (our data flow)"
  annotations={``}
/>

The map operation is one of the array methods available in Rust, that get an argument (`|x|`) and
return a value. If we don't perform anything fancy, we can just specify the shortened version of
the returning a value (an expression that **doesn't end with semicolon**). Anything more complicated
can be enclosed in a separate scope i.e. curly braces. So, the following code snippets are equivalent:

<CodeSnippet
  code={`
    let a: Vec<i64> = vec![1, 2, 3, 4, 5];
    let b: Vec<i64> = a.iter().map(|x| x * 2).collect();
  `}
  language="rust"
  filename="map method"
  annotations={`
    2: We iterate over the vector of i64 values, multiply and return
  `}
/>

<CodeSnippet
  code={`
    let a: Vec<i64> = vec![1, 2, 3, 4, 5];
    let b: Vec<i64> = a.iter().map(|x| {
      let y = x * 2;
      y
    }).collect();
  `}
  language="rust"
  filename="map method (with scope)"
  annotations={`
    2: We iterate over the vector of i64 values
    3: For each value, we multiply it by 2
    5: We collect the results into a new vector
  `}
/>

All batch operations that can be performed on iterable containers of data can be checked out 
in the documentation of [`Iterator` trait from the standard library]. I highly recommend it. üòâ

#### Implementing Atom 3: The Return of the `impl` üßé‚Äç‚ôÇÔ∏è

Using the `to_vec_f64` function, we can now implement the `from` method for the `Atom` structure,
while also using the wisdom we've gained while parsing the YAML script inside this function definition:

<CodeSnippet
  code={`
    ...
    pub fn from(yaml: &yaml_rust::Yaml) -> Atom {
        let mut atom = Atom::new();
        atom.current.position = to_vec3(&yaml["position"]);
        atom.current.velocity = match &yaml["velocity"] {
            yaml_rust::Yaml::Array(_x) => to_vec3(&yaml["velocity"]),
            _ => Vector3::zeros(),
        };
        atom.current.force = match &yaml["force"] {
            yaml_rust::Yaml::Array(_x) => to_vec3(&yaml["force"]),
            _ => Vector3::zeros(),
        };
        atom.name = String::from(yaml["name"].as_str().unwrap());
        atom.mass = match &yaml["mass"] {
            yaml_rust::Yaml::Real(x) => x.parse::<f64>().unwrap(),
            yaml_rust::Yaml::String(x) => x.parse::<f64>().unwrap(),
            yaml_rust::Yaml::Integer(x) => *x as f64,
            yaml_rust::Yaml::BadValue => {
                match periodic_table_on_an_enum::Element::from_symbol(atom.name.as_str()) {
                    Some(x) => x.get_atomic_mass().into(),
                    None => panic!("Failed to find mass for element {}!", atom.name),
                }
            }
            _ => panic!("Failed to find mass for element {}!", atom.name),
        };
        atom.charge = match &yaml["charge"] {
            yaml_rust::Yaml::Integer(x) => *x as f64,
            yaml_rust::Yaml::Real(x) => x.parse::<f64>().unwrap(),
            yaml_rust::Yaml::String(x) => x.parse::<f64>().unwrap(),
            yaml_rust::Yaml::BadValue => 0.0,
            _ => panic!("Incorrect charge for element {}!", atom.name),
        };
        atom
      }
    ...
  `}
  language="rust"
  filename="system/atom.rs (from method)"
  annotations={`
    2: REFERENCE to YAML, so it doesn't wither away üíÄ
    3: Create new instance of Atom and make it modifiable
    4: Position is required do we know we should parse it to Vector3
    5-8: Velocity is optional, so if it is not defined, we set it to zeros
    9-12: Same with force vector
    13: We 100% need the name of the atom, so there is no match statement
    14-24: Here if the mass is given, parse it if not - try to read it from the periodic table
    26-32: If charge is set - parse it and pass to the atom, otherwise - it is inert
    33: We return the constructed atom
  `}
/>

Cool, now initialize our atoms from the YAML script. The last utility function we can add is
the `.clone()` operator which will become useful in a second, when creating replicas of atoms
during the generation of the simulation box. After adding that function, we can move to
defining our system shape etc.

<CodeSnippet
  code={`
    use periodic_table_on_an_enum::Element;
    use nalgebra::Vector3;

    use crate::io::input::to_vec3;

    #[derive(Debug)]
    pub struct CurrentState {
        pub position: Vector3<f64>,
        pub velocity: Vector3<f64>,
        pub force: Vector3<f64>,
        pub potential_energy: f64,
        pub kinetic_energy: f64,
        pub total_energy: f64,
    }

    #[derive(Debug)]
    pub struct PreviousState {
        pub position: Vector3<f64>,
        pub velocity: Vector3<f64>,
        pub force: Vector3<f64>,
        pub potential_energy: f64,
        pub kinetic_energy: f64,
        pub total_energy: f64,
    }

    impl CurrentState {
        pub fn cache(&self) -> PreviousState {
            PreviousState {
                position: self.position,
                velocity: self.velocity,
                force: self.force,
                potential_energy: self.potential_energy,
                kinetic_energy: self.kinetic_energy,
                total_energy: self.total_energy,
            }
        }
    }

    #[derive(Debug)]
    pub struct Atom {
        pub id: u64,
        pub name: String,
        pub previous: PreviousState,
        pub current: CurrentState,
        pub mass: f64,
        pub charge: f64,
    }

    impl Atom {
        pub fn new() -> Atom {
            Atom {
                id: 0,
                previous: PreviousState {
                    position: Vector3::zeros(),
                    velocity: Vector3::zeros(),
                    force: Vector3::zeros(),
                    potential_energy: 0.0,
                    kinetic_energy: 0.0,
                    total_energy: 0.0,
                },
                current: CurrentState {
                    position: Vector3::zeros(),
                    velocity: Vector3::zeros(),
                    force: Vector3::zeros(),
                    potential_energy: 0.0,
                    kinetic_energy: 0.0,
                    total_energy: 0.0,
                },
                mass: 1.0,
                charge: 0.0,
                name: String::from("NaN"),
            }
        }
        pub fn from(yaml: &yaml_rust::Yaml) -> Atom {
            let mut atom = Atom::new();
            atom.current.position = to_vec3(&yaml["position"]);
            atom.current.velocity = match &yaml["velocity"] {
                yaml_rust::Yaml::Array(_x) => to_vec3(&yaml["velocity"]),
                _ => Vector3::zeros(),
            };
            atom.current.force = match &yaml["force"] {
                yaml_rust::Yaml::Array(_x) => to_vec3(&yaml["force"]),
                _ => Vector3::zeros(),
            };
            atom.name = String::from(yaml["name"].as_str().unwrap());
            atom.mass = match &yaml["mass"] {
                yaml_rust::Yaml::Real(x) => x.parse::<f64>().unwrap(),
                yaml_rust::Yaml::String(x) => x.parse::<f64>().unwrap(),
                yaml_rust::Yaml::Integer(x) => *x as f64,
                yaml_rust::Yaml::BadValue => {
                    match Element::from_symbol(atom.name.as_str()) {
                        Some(x) => x.get_atomic_mass().into(),
                        None => panic!("Failed to find mass for element {}!", atom.name),
                    }
                }
                _ => panic!("Failed to find mass for element {}!", atom.name),
            };
            atom.charge = match &yaml["charge"] {
                yaml_rust::Yaml::Integer(x) => *x as f64,
                yaml_rust::Yaml::Real(x) => x.parse::<f64>().unwrap(),
                yaml_rust::Yaml::String(x) => x.parse::<f64>().unwrap(),
                yaml_rust::Yaml::BadValue => 0.0,
                _ => panic!("Incorrect charge for element {}!", atom.name),
            };
            atom
        }
        pub fn clone(&self) -> Atom {
            Atom {
                id: self.id,
                name: self.name.clone(),
                current: CurrentState {
                    position: self.current.position,
                    velocity: self.current.velocity,
                    force: self.current.force,
                    potential_energy: self.current.potential_energy,
                    kinetic_energy: self.current.kinetic_energy,
                    total_energy: self.current.total_energy,
                },
                previous: PreviousState {
                    position: self.previous.position,
                    velocity: self.previous.velocity,
                    force: self.previous.force,
                    potential_energy: self.previous.potential_energy,
                    kinetic_energy: self.previous.kinetic_energy,
                    total_energy: self.previous.total_energy,
                },
                mass: self.mass,
                charge: self.charge,
            }
        }
    }
  `}
  language="rust"
  filename="system/atom.rs (with clone method)"
  annotations={`
    6: Ignore this for now üôà
    16: This too, we will get to it in a second
    39: This also can be ignored for now
    110: String has to be cloned since it is a reference to an array of characters
    111-126: We instantiate new state objects using data held by an atom
  `}
/>

Having implemented the occupants of our little, molecular world we can move to
creating their microscopic home - the simulation box.

### Boxing the infinite ‚ôæÔ∏è üëâ üì¶

Going back to the general idea of the simulation box, it should be composed of
**unit cells** (tiles) that are repeated along **their** dimensions to form
a three-dimensional grid (pattern). The space occupied by this grid will be
the simulation box.

This leads us to our first structure used to define the shape of the system - the `UnitCell` structure,
which will be implemented in the `cell.rs` file, like so:

<CodeSnippet
  code={`
    use nalgebra::Matrix3;
    use nalgebra::Vector3;

    pub struct UnitCell {
        pub vectors: Matrix3<f64>,
        pub constants: Vector3<f64>,
        pub volume: f64,
    }

    impl UnitCell {
        pub fn new(vectors: Matrix3<f64>) -> UnitCell {
            let mut initialized_cell = UnitCell {
                vectors,
                constants: Vector3::zeros(),
                volume: 0.0,
            };
            initialized_cell.constants = Vector3::new(
                vectors.row(0).norm(),
                vectors.row(1).norm(),
                vectors.row(2).norm(),
            );
            initialized_cell.volume = vectors.determinant();
            initialized_cell
        }
    }
  `}
  language="rust"
  filename="system/cell.rs"
  annotations={`
    1: We will use matrix with 3 rows and 3 columns to define the unit cell
    2: Each edge of unit cell will be described with a vector
    17-21: We will use the "norm" method to calculate the length of each vector i.e. dimensions of unit cell
    22: str8 maths - the determinant of a matrix containing vectors of edges of a parallelepiped is equal to its volume
  `}
/>

There is nothing extraordinary about this implementation, but here we can introduce one little thing in Rust.
**TRAITS**.

#### Particle No. 8 - If it quacks like a struct, it's probably a struct ü¶Ü

In object-oriented programming, a prevalent example about common behavior shared by different objects
is the `Animal` class. It is a class that defines the common behavior of animals, like `eat` or `sleep`.
Dogs sleep and eat, ducks sleep and eat, cats sleep and eat, so they all can be described as animals.
Each animal sleeps and eats in its own way. We ain't about happy farms here, we juggle data and
print esoteric information to the screen in electronic moonspeak. üåõ

I want to print my `UnitCell` to standard output, so I can see its vectors - for debugging purposes.
If I try to put an instance of `UnitCell` into the `println!` macro, I will get an error:

<CaptionedImage
  src="/assets/images/unitcell_notrait.png"
  alt="Rust compilation errors are actually helpful, they suggest what we messed up üò±"
/>

Just look at the **help** part of the message. It says that the `UnitCell` structure doesn't implement
the `std::fmt::Display` trait. What is a trait? It is a **set of methods** (behavior) that can be
implemented by a structure. So, if we want to print our `UnitCell` to standard output, we have to
implement the `Display` trait for it. This trait is defined in the `std::fmt` module of the standard library,
so we don't have to import anything, we only need to reference it in the `impl` block:

<CodeSnippet
  code={`
    use nalgebra::Matrix3;
    use nalgebra::Vector3;

    use std::fmt;

    pub struct UnitCell {
        pub vectors: Matrix3<f64>,
        pub constants: Vector3<f64>,
        pub volume: f64,
    }

    impl UnitCell {
        pub fn new(vectors: Matrix3<f64>) -> UnitCell {
            let mut initialized_cell = UnitCell {
                vectors,
                constants: Vector3::zeros(),
                volume: 0.0,
            };
            initialized_cell.constants = Vector3::new(
                vectors.row(0).norm(),
                vectors.row(1).norm(),
                vectors.row(2).norm(),
            );
            initialized_cell.volume = vectors.determinant();
            initialized_cell
        }
    }

    impl std::fmt::Display for UnitCell {
        fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
            let definition = format!("\\n  Vectors: {:?}\\n ", self.vectors);
            write!(f, "{}", definition)
        }
    }
  `}
  language="rust"
  filename="system/cell.rs (with Display trait)"
  annotations={`
    31:Here we use the Debug formatter "?", I will explain it in a second
    32:This method must return a Result type, so we use the "write" method to write to the formatter
  `}
/>

The `fmt` method inside this `std::fmt::Display` trait implementation is the method that will be called
when we try to print our `UnitCell` to standard output. It takes two arguments:

- `f` - a formatter that will be used to write the data to the output
- `self` - a reference to the `UnitCell` instance that we want to print

The `f` argument is a reference to the `std::fmt::Formatter` structure - a handler that
controls where and how the output is to be written. The rule of thumbs is as follows:

**Prepare a string with the output and then pass it to the `write!` macro, which will
try to push Your information to the formatter.**

Macros are written with the `!` symbol at the end of their name. They are basically
functions that are called at compile time and can be used to generate code. For now,
treat them as "magic" functions that obfuscate some more complicated code. üòÖ

So, what's up with the `?` symbol? It is a **shortcut** for the `Debug` formatter, which
is another trait that can be implemented for a structure. It is just a more verbose `Display`.
We can choose to implement it explicitly via another `impl` block or use a very handy
`derive` attribute, which will automatically implement the `Debug` trait for us. 
It is also a macro (an **attribute macro**) that is
**VERY** similar to Python decorators. We can use it on our `UnitCell` structure like so:

<CodeSnippet
  code={`
    use nalgebra::Matrix3;
    use nalgebra::Vector3;

    #[derive(Debug)]
    pub struct UnitCell {
        pub vectors: Matrix3<f64>,
        pub constants: Vector3<f64>,
        pub volume: f64,
    }

    ... // The rest stays the same
  `}
  language="rust"
  filename="system/cell.rs (with Debug trait)"
  annotations={`
    3: This is the macro that generated the Debug trait implementation for us
  `}
/>

At the compilation time, the compiler will automatically generate the `impl std::fmt::Debug for UnitCell`
shebang for us. It is very naive, since it will just do the presentation of our structure
in a `field: value` type of way, but hey! It is for debugging purposes, so it will do.

This is a very common pattern in Rust, where code can be effectively injected into
our source code! Now both `"{}"` and `"{:?}"` formatters will work for our `UnitCell` structure,
when invoking them in the `println!` macro. **YES**, the printing "function" we've been using so far
is also a macro. They are a powerful tool, so I really recommend [checking them out e.g. in the
official Rust book].

With the unit cell done, we can switch to the simulation box definition. It will be defined
in another source code file called `box.rs`.

#### Perfection through repetition üîÑ

The simulation box will be defined by the `SimulationBox` structure, which will be composed of
definition of our unit cell, the number of unit cells in each dimension and the resulting
dimensions of the constructed box, after we tile the cells together.

<CodeSnippet
  code={`
    use nalgebra::Matrix3;
    use nalgebra::Vector3;

    use crate::system::cell::UnitCell;

    #[derive(Debug)]
    pub struct SimulationBox {
        pub cell: UnitCell,
        pub vectors: Matrix3<f64>,                // Simulation box vectors
        pub versors: Matrix3<f64>,                // Simulation box versors
        pub dimensions: Vector3<f64>,             // Dimensions of the simulation box
        pub replicas: [usize; 3],                 // Number of replicas in each direction
        pub periodicity: [bool; 3],               // Periodicity of the simulation box
        pub change_of_basis_matrix: Matrix3<f64>, // Matrix mapping between global coordinates and simulation box coordinates
    }

    impl SimulationBox {
        pub fn new(
            vectors: Matrix3<f64>,
            periodicity: [bool; 3],
            replicas: [usize; 3],
        ) -> SimulationBox {
            let mut new_box = SimulationBox {
                cell: UnitCell::new(vectors),
                vectors: Matrix3::zeros(),
                versors: Matrix3::zeros(),
                dimensions: Vector3::zeros(),
                replicas,
                periodicity,
                change_of_basis_matrix: Matrix3::zeros(),
            };
            new_box.calculate_box_vectors();
            new_box.calculate_mapping_matrix();
            new_box
        }

        fn calculate_box_vectors(&mut self) -> () {
          ...
        }

        fn calculate_mapping_matrix(&mut self) -> () {
          ...
        }

        pub fn wrap_position(&self, position: Vector3<f64>) -> Vector3<f64> {
          ...
        }

        pub fn map_vector_to_box_basis(&self, vector: &Vector3<f64>) -> Vector3<f64> {
            self.change_of_basis_matrix * vector
        }

        pub fn map_vector_to_system_basis(&self, vector: &Vector3<f64>) -> Vector3<f64> {
            self.change_of_basis_matrix.try_inverse().unwrap() * vector
        }
    }
  `}
  language="rust"
  filename="system/box.rs"
  annotations={`
    4: We import our UnitCell implementation here (crate is the root of our project)
    36-48: This will be implemented later
  `}
/>

The most important methods here are `calculate_box_vectors` and `calculate_mapping_matrix`.
They are connected to a very important aspect of defining how our atoms are located in the system
during a specific moment in time and if they will reside inside out simulation box or not.

#### A matter of coordination ü§ù

Basically, we are now working in two, separate coordination systems:

- **Global** - the system of coordinates that is used to define the position of atoms in the simulation box
  based on the Cartesian coordinate system, so right angles between each axes and each vector component is basically
  a number
- **Box** - the system of coordinates that is used to define the position of atoms in the simulation box
  based on the **unit cell** vectors, so the edges of the unit cell and each vector component are a number
  between 0 and 1 meaning **how many of each unit cell vector** is needed to reach the atom from the origin

// Tutaj obrazek z dwoma uk≈Çadami wsp√≥≈Çrzƒôdnych

The difference between them is **significant** because there is no restriction made on the box coordinates
when it comes to the angles between each axis - the simulation box can be skewed. We will see later,
that ensuring the "pacmaneque" behaviour of atoms in the simulation box is much easier when working
in the box coordinates, so we will have to convert the global coordinates to box coordinates and vice versa.

This is a standard problem in linear algebra, where we have to find a **mapping** between two coordinate systems or,
in other words, a **[change of basis]** matrix. This matrix will be used to convert the global coordinates
to box coordinates and vice versa. The `calculate_mapping_matrix` method will calculate this matrix
and store it in the `change_of_basis_matrix` field of the `SimulationBox` structure.

In practice, this procedure is rather simple to implement **if we have a proper linear algebra library** üòâ.
We can use the `nalgebra` library to do the heavy lifting for us. The `calculate_mapping_matrix` method
is implemented in the `box.rs` file like so:

<CodeSnippet
  code={`
    fn calculate_mapping_matrix(&mut self) -> () {
        let change_of_basis_matrix = self.vectors.normalize();
        match change_of_basis_matrix.try_inverse() {
            Some(_) => self.change_of_basis_matrix = change_of_basis_matrix,
            None => panic!("Could not invert change of basis matrix"),
        }
    }
  `}
  language="rust"
  filename="system/box.rs (calculate_mapping_matrix method)"
  annotations={`
    2: We normalize the vectors of the simulation box, so they are of unit length
    3: We try to invert the matrix, if it is invertible, we store it in the structure
    5: If it is not invertible, we panic
  `}
/>

The invertibility of the matrix is checked by the `try_inverse` method, which returns `None` if the matrix
is not invertible. If it is invertible, we store the original matrix in the `change_of_basis_matrix` field of the `SimulationBox`.
Why it should be able to be inverted though?

[In short], when we construct the matrix using **unit cell vectors defined in global coordinates**,
we effectively do the mapping from the **box coordinates** to **global coordinates**. If we invert
this matrix, we will get the mapping from **global coordinates** to **box coordinates**. This is exactly
what we need to do. Both of these operations are separated into `map_vector_to_box_basis` and
`map_vector_to_system_basis` methods, for convenience really. You can see here that `nalgebra` library
is really powerful, since it allows us to perform matrix-vector multiplication with ease.

But where we will get the simulation box vectors from? We can calculate them from the unit cell vectors
and the number of replicas in each dimension. The `calculate_box_vectors` method will do just that.
Also, note the cool, tuple-like indexing of single elements of `Matrix3` objects. It is another nice
feature of the `nalgebra` library. üëç

<CodeSnippet
  code={`
    fn calculate_box_vectors(&mut self) -> () {
        let mut new_vectors = self.cell.vectors.clone();
        for i in 0..3 {
            new_vectors[(i, i)] *= self.replicas[i] as f64;
        }
        let new_dimensions: Vector3<f64> = Vector3::new(
            new_vectors.row(0).norm(),
            new_vectors.row(1).norm(),
            new_vectors.row(2).norm(),
        );
        let mut new_versors = Matrix3::<f64>::zeros();
        for i in 0..3 {
            for j in 0..3 {
                new_versors[(i, j)] = new_vectors[(i, j)] * (1.0 / new_dimensions[i]);
            }
        }
        self.vectors = new_vectors;
        self.dimensions = new_dimensions;
        self.versors = new_versors;
    } 
  `}
  language="rust"
  filename="system/box.rs (calculate_box_vectors method)"
  annotations={`
    2: We clone the unit cell vectors, so we can modify them
    3-5: We multiply each vector by the number of replicas in each dimension
    6-10: We calculate the dimensions of the simulation box
    11-16: We calculate the versors of the simulation box
    17-19: We store the calculated vectors, dimensions and versors in the structure
  `}
/>

The only thing left is throwing in nice `Display` for our box and we're done here. üéâ

<CodeSnippet
  code={`
    use nalgebra::Matrix3;
    use nalgebra::Vector3;

    use crate::system::cell::UnitCell;

    #[derive(Debug)]
    pub struct SimulationBox {
        pub cell: UnitCell,
        pub vectors: Matrix3<f64>,                // Simulation box vectors
        pub versors: Matrix3<f64>,                // Simulation box versors
        pub dimensions: Vector3<f64>,             // Dimensions of the simulation box
        pub replicas: [usize; 3],                 // Number of replicas in each direction
        pub periodicity: [bool; 3],               // Periodicity of the simulation box
        pub change_of_basis_matrix: Matrix3<f64>, // Matrix mapping between global coordinates and simulation box coordinates
    }

    impl SimulationBox {
        pub fn new(
            vectors: Matrix3<f64>,
            periodicity: [bool; 3],
            replicas: [usize; 3],
        ) -> SimulationBox {
            let mut new_box = SimulationBox {
                cell: UnitCell::new(vectors),
                vectors: Matrix3::zeros(),
                versors: Matrix3::zeros(),
                dimensions: Vector3::zeros(),
                replicas,
                periodicity,
                change_of_basis_matrix: Matrix3::zeros(),
            };
            new_box.calculate_box_vectors();
            new_box.calculate_mapping_matrix();
            new_box
        }

        fn calculate_box_vectors(&mut self) -> () {
            let mut new_vectors = self.cell.vectors.clone();
            for i in 0..3 {
                new_vectors[(i, i)] *= self.replicas[i] as f64;
            }
            let new_dimensions: Vector3<f64> = Vector3::new(
                new_vectors.row(0).norm(),
                new_vectors.row(1).norm(),
                new_vectors.row(2).norm(),
            );
            let mut new_versors = Matrix3::<f64>::zeros();
            for i in 0..3 {
                for j in 0..3 {
                    new_versors[(i, j)] = new_vectors[(i, j)] * (1.0 / new_dimensions[i]);
                }
            }
            self.vectors = new_vectors;
            self.dimensions = new_dimensions;
            self.versors = new_versors;
        }

        fn calculate_mapping_matrix(&mut self) -> () {
            let change_of_basis_matrix = self.vectors.normalize();
            match change_of_basis_matrix.try_inverse() {
                Some(_) => self.change_of_basis_matrix = change_of_basis_matrix,
                None => panic!("Could not invert change of basis matrix"),
            }
        }

        pub fn wrap_position(&self, position: Vector3<f64>) -> Vector3<f64> {
            let wrapped_position = position.clone();
            wrapped_position
        }

        pub fn map_vector_to_box_basis(&self, vector: &Vector3<f64>) -> Vector3<f64> {
            self.change_of_basis_matrix * vector
        }

        pub fn map_vector_to_system_basis(&self, vector: &Vector3<f64>) -> Vector3<f64> {
            self.change_of_basis_matrix.try_inverse().unwrap() * vector
        }
    }

    impl std::fmt::Display for SimulationBox {
        fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
            let definition = format!(
                "Vectors: {:?}\\n  Replicas: {:?}\\n  Periodicity: {:?}\\n",
                self.vectors, self.replicas, self.periodicity
            );
            write!(f, "{}", definition)
        }
    }
  `}
  language="rust"
  filename="system/box.rs (complete)"
  annotations={`
    66-69: A dummy implementation, we will come back to it later
  `}
/>

### Spreading a wide net üï∏Ô∏è

We've loaded our atoms and constructed the box in which they will reside. The next logical thing is
to combine those two entities to form a fully-fledged atomic structure. Just like our basic cell shape,
the pattern made by the atoms within it will be repeated along the dimensions of the simulation box.
The resulting structure has its name in a branch of physics (more specifically, solid-state physics)
of crystallography - **crystal lattice**. 

This ordered way in which matter groups itself
is one of the main reasons why different materials possess different properties. Dense crystal
lattices are responsible for the hardness of diamonds, while loosely and/or chaotic packed structures
result in more flexible things like rubber. Solid-state physics is a very interesting field of study
especially when You get into nitty-gritty specifics of how, for example, metal alloys are created
and how they withstand the forces applied to them. I highly recommend checking it out, that was
one of my main focuses during my doctorate - [simulating and predicting properties of aluminum and copper alloys].

To perform the construction of the crystal lattice, we will use the `lattice.rs` file that will not hold
any specific structures, but will be a small collection of functions that will be used to place atoms within
a given unit cell and then replicate them along the dimensions of the simulation box. The first function
will be called `scale_cell_basis` and will be used to scale the relative coordinates of atoms using
the basic vectors of the cell:

<CodeSnippet
  code={`
    use rayon::prelude::*;

    use nalgebra::Vector3;

    use crate::system::atom::Atom;
    use crate::system::r#box::SimulationBox;

    pub fn scale_cell_basis(atoms: &mut Vec<Atom>, simulation_box: &SimulationBox) -> () {
        println!("Scaling cell basis");
        atoms.par_iter_mut().for_each(|atom| {
            let mut scaled_position = Vector3::<f64>::zeros();
            for i in 0..3 {
                scaled_position[i] = atom.current.position[i] * simulation_box.cell.vectors[(i, i)];
            }
            atom.current.position = scaled_position;
        });
    }    
  `}
  language="rust"
  filename="system/lattice.rs (scale_cell_basis function)"
  annotations={`
    1: Umm... rayon? What is that?
    10: par_iter_mut?
  `}
/>

At the first glance, it makes sense - we modify the position of each atom by multiplying each component
of the position vector by the corresponding component of the unit cell vector (hence the `&mut Vec<Atom>`).
But, what is this `rayon` thing?

#### Particle No. 9 - Everything, everywhere, all at once üëÅÔ∏è

Imagine there is, like, thousands of atoms in our system. We want to modify their positions
in the simulation box. We can do it sequentially, one by one, but that would be very slow.
Now imagine we have more than one CPU thread in our computers that are specifically designed
to carry out independent operations, that can be performed in parallel. Sike, there is nothing
to imagine - they have reached the mainstream, gaming culture since the dawn of Crysis and
have been used in scientific computing for decades. We can utilize them to speed up our
calculations. The `rayon` library offers high-level parallel constructs or, in other words,
ways to spawn separate tasks performed on multiple threads without touching the MPI documentation üòå.

The `par_iter_mut` method is a method that is used to iterate over a collection of data
in parallel. Each element can be mutated (hence the `_mut` suffix), so we can modify the position of each atom
independently via standard higher-order functions like `map` or `for_each`. So if we run this code
and then inspect our CPU usage using tools like `htop`, we will see that all of our CPU cores
are being utilized to perform the calculations.

<CaptionedImage
  src="/assets/images/rayon.png"
  alt="Multiple threads of the program running in parallel"
/>


And that's it really for the basics. Of course, there are more advanced aspects like using **too much**
CPU cores, which can lead to **slower** calculations, but for now - this is enough. If we run to
optimization problems in the future, we will deal with them when the time comes (and it always comes üòÖ).
Later, we will use the `par_iter_mut` method to perform more complicated operations on our atoms,
but it is nice to introduce it here, so we can get used to it. üòâ

The [parallel iterator] appears once more in the `lattice.rs` file, namely in the function
that replicates the atoms along the dimensions of the simulation box:

<CodeSnippet
  code={`
    pub fn generate_lattice(atoms: &mut Vec<Atom>, simulation_box: &SimulationBox) -> () {
        println!("Generating lattice");
        let original_atoms_length = atoms.len();
        let x_replicas = simulation_box.replicas[0];
        let y_replicas = simulation_box.replicas[1];
        let z_replicas = simulation_box.replicas[2];

        let x_vector: Vector3<f64> = Vector3::new(
            simulation_box.cell.vectors[(0, 0)],
            simulation_box.cell.vectors[(0, 1)],
            simulation_box.cell.vectors[(0, 2)],
        );

        let y_vector: Vector3<f64> = Vector3::new(
            simulation_box.cell.vectors[(1, 0)],
            simulation_box.cell.vectors[(1, 1)],
            simulation_box.cell.vectors[(1, 2)],
        );

        let z_vector: Vector3<f64> = Vector3::new(
            simulation_box.cell.vectors[(2, 0)],
            simulation_box.cell.vectors[(2, 1)],
            simulation_box.cell.vectors[(2, 2)],
        );

        let mut generated_atoms = Vec::new();
        for x in 0..x_replicas {
            for y in 0..y_replicas {
                for z in 0..z_replicas {
                    if x == 0 && y == 0 && z == 0 {
                        continue;
                    }
                    let mut replica_atoms: Vec<Atom> = atoms
                        .par_iter()
                        .map(|atom| {
                            let mut new_atom = atom.clone();
                            new_atom.current.position += x as f64 * x_vector;
                            new_atom.current.position += y as f64 * y_vector;
                            new_atom.current.position += z as f64 * z_vector;
                            new_atom
                        })
                        .collect::<Vec<Atom>>();
                    generated_atoms.append(&mut replica_atoms);
                }
            }
        }
        atoms.append(&mut generated_atoms);
        let new_atoms_length = atoms.len();
        println!(
            "Generated {} atoms",
            new_atoms_length - original_atoms_length
        );
        atoms
            .par_iter_mut()
            .enumerate()
            .for_each(|(index, atom)| atom.id = index as u64);
      }
  `}
  language="rust"
  filename="system/lattice.rs (generate_lattice function)"
  annotations={`
    53-56: Here we relabel the atoms, so they have unique IDs
  `}
/>

For the part of the code with triple-nested loop, I recommend checking out the definition of
[Bravais Lattice], which is used to generate the crystal lattice mathematically.

## The "kind-of" big picture

## What's next?

[Python bindings for MPI]: https://mpi4py.readthedocs.io/en/stable/
[they are still arrays with sizes known at compile time]: https://nalgebra.org/docs/user_guide/vectors_and_matrices/
[generic parameter]: https://doc.rust-lang.org/reference/items/generics.html
[`Iterator` trait from the standard library]: https://doc.rust-lang.org/std/iter/trait.Iterator.html
[checking them out e.g. in the official Rust book]: https://doc.rust-lang.org/book/ch19-06-macros.html
[change of basis]: https://en.wikipedia.org/wiki/Change_of_basis
[In short]: https://math.stackexchange.com/questions/1818527/verification-of-change-of-basis-calculation
[simulating aluminum and copper alloys]: https://mostwiedzy.pl/pl/publication/improvements-to-the-two-phase-sandwich-method-for-calculating-the-melting-points-of-pure-metals,149990-1
[parallel iterator]: https://docs.rs/rayon/latest/rayon/iter/trait.ParallelIterator.html
[Bravais Lattice]: https://www.physics-in-a-nutshell.com/article/4/lattice-basis-and-crystal
